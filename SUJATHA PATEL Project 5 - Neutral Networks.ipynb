{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECE SUBMISSION BY SUJATHA PATEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Churn Prediction\n",
    "\n",
    "### Objective:\n",
    "Given a Bank customer, build a neural network based classifier that can determine whether they will leave\n",
    "or not in the next 6 months.\n",
    "\n",
    "### Context:\n",
    "Businesses like banks which provide service have to worry about problem of 'Churn' i.e. customers\n",
    "leaving and joining another service provider. It is important to understand which aspects of the service\n",
    "influence a customer's decision in this regard. Management can concentrate efforts on improvement of\n",
    "service, keeping in mind these priorities.\n",
    "\n",
    "### Data Description:\n",
    "The case study is from an open-source dataset from Kaggle.\n",
    "The dataset contains 10,000 sample points with 14 distinct features such as CustomerId, CreditScore,\n",
    "Geography, Gender, Age, Tenure, Balance etc.\n",
    "\n",
    "### Link to the Kaggle project site:\n",
    "https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling\n",
    "\n",
    "### Points Distribution:\n",
    "The points distribution for this case is as follows:\n",
    "1. Read the dataset\n",
    "2. Drop the columns which are unique for all users like IDs (5 points)\n",
    "3. Distinguish the features and target variable (5 points)\n",
    "4. Divide the data set into training and test sets (5 points)\n",
    "5. Normalize the train and test data (10 points)\n",
    "6. Initialize & build the model. Identify the points of improvement and implement the same the same.(20)\n",
    "7. Predict the results using 0.5 as a threshold (10 points)\n",
    "8. Print the Accuracy score and confusion matrix (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install tensorflow (run at anaconda3)\n",
    "# conda install keras  (run at anaconda3)\n",
    "# conda install seaborn (run at anaconda3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized function to find the skewness, outliers of all columns\n",
    "def cdescribe(df):\n",
    "  results = []\n",
    "  for col in df.select_dtypes(include = ['float64', 'int64']).columns.tolist():\n",
    "    stats = OrderedDict({'': col, \n",
    "                         'Count': df[col].count(), \n",
    "                         'Type': df[col].dtype, \n",
    "                         'Mean': round(df[col].mean(), 2), \n",
    "                         'StdDev': round(df[col].std(), 2), \n",
    "                         'Variance': round(df[col].var(), 2), \n",
    "                         'Minimum': round(df[col].min(), 2), \n",
    "                         'Q1': round(df[col].quantile(0.25), 2), \n",
    "                         'Median': round(df[col].median(), 2), \n",
    "                         'Q3': round(df[col].quantile(0.75), 2), \n",
    "                         'Maximum': round(df[col].max(), 2),\n",
    "                         'Range': round(df[col].max(), 2)-round(df[col].min(), 2), \n",
    "                         'IQR': round(df[col].quantile(0.75), 2)-round(df[col].quantile(0.25), 2),\n",
    "                         'Kurtosis': round(df[col].kurt(), 2), \n",
    "                         'Skewness': round(df[col].skew(), 2), \n",
    "                         'MeanAbsDev': round(df[col].mad(), 2)})\n",
    "    if df[col].skew() < -1:\n",
    "      if df[col].median() < df[col].mean(): ske = 'Highly Skewed (Right)'      \n",
    "      else: ske = 'Highly Skewed (Left)'\n",
    "    elif -1 <= df[col].skew() <= -0.5:\n",
    "      if df[col].median() < df[col].mean(): ske = 'Moderately Skewed (Right)'\n",
    "      else: ske = 'Moderately Skewed (Left)'\n",
    "    elif -0.5 < df[col].skew() <= 0:  \n",
    "      if df[col].median() < df[col].mean(): ske = 'Fairly Symmetrical (Right)'\n",
    "      else: ske = 'Fairly Symmetrical (Left)' \n",
    "    elif 0 < df[col].skew() <= 0.5:\n",
    "      if df[col].median() < df[col].mean(): ske = 'Fairly Symmetrical (Right)'\n",
    "      else: ske = 'Fairly Symmetrical (Left)'\n",
    "    elif 0.5 < df[col].skew() <= 1:\n",
    "      if df[col].median() < df[col].mean(): ske = 'Moderately Skewed (Right)'\n",
    "      else: ske = 'Moderately Skewed (Left)'\n",
    "    elif df[col].skew() > 1:\n",
    "      if df[col].median() < df[col].mean(): ske = 'Highly Skewed (Right)'\n",
    "      else: ske = 'Highly Skewed (Left)'\n",
    "    else:\n",
    "      ske = 'Error'\n",
    "    stats['SkewnessComment'] = ske\n",
    "    upper_lim, lower_lim = stats['Q3'] + (1.5 * stats['IQR']), stats['Q1'] - (1.5 * stats['IQR'])\n",
    "    if len([x for x in df[col] if x < lower_lim or x > upper_lim])>1:\n",
    "      out = 'HasOutliers'\n",
    "    else:\n",
    "      out = 'NoOutliers'\n",
    "    stats['OutliersComment'] = out\n",
    "    results.append(stats)\n",
    "    if df[col].median() > df[col].mean():\n",
    "       med_mean = \"more than\"\n",
    "    elif df[col].median() < df[col].mean():\n",
    "       med_mean = \"less than\"\n",
    "    else:\n",
    "       med_mean = \"same as\"\n",
    "\n",
    "    # Printi the descriptive statistics report for all the columns in concrete dataset\n",
    "    print(f'\\n{col} - Data ranges between {round(df[col].min(),2)} to {round(df[col].max(),2)}, while 25th and 75th percentile is spread between {round(df[col].quantile(0.25),2)} to {round(df[col].quantile(0.75),2)}. Median {round(df[col].median(),2)} is {med_mean} than Mean {round(df[col].mean(),2)} which means cement is {ske}. Column has {out}.')\n",
    "  \n",
    "  describe = pd.DataFrame(results).set_index('')\n",
    "              \n",
    "  return display(describe.T)\n",
    "\n",
    "def unique(df): \n",
    "  \n",
    "    # intilize a null list \n",
    "    unique_list = [] \n",
    "      \n",
    "    # traverse for all elements \n",
    "    for x in df.columns: \n",
    "        print(x,df[x].nunique())\n",
    "        \n",
    "\n",
    "def bdplots(df, col):\n",
    "    f,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (15, 7))\n",
    "    \n",
    "    # Boxplot to check outliers\n",
    "    sns.boxplot(x = col, data = df, ax = ax1, orient = 'v', color = 'lightblue')\n",
    "    \n",
    "    # Distribution plot with outliers\n",
    "    sns.distplot(df[col], ax = ax2, color = 'teal', fit = norm, rug = True).set_title(f'{col} with outliers')\n",
    "    ax2.axvline(df[col].mean(), color = 'r', linestyle = '--', label = 'Mean', linewidth = 1.2)\n",
    "    ax2.axvline(df[col].median(), color = 'g', linestyle = '--', label = 'Median', linewidth = 1.2)\n",
    "    ax2.axvline(df[col].mode()[0], color = 'b', linestyle = '--', label = 'Mode', linewidth = 1.2); ax2.legend(loc = 'best')\n",
    "    \n",
    "    # Removing outliers, but in a new dataframe\n",
    "    upperbound, lowerbound = np.percentile(df[col], [1, 99])\n",
    "    y = pd.DataFrame(np.clip(df[col], upperbound, lowerbound))\n",
    "    \n",
    "    # Distribution plot without outliers\n",
    "    sns.distplot(y[col], ax = ax3, color = 'tab:orange', fit = norm, rug = True).set_title(f'{col} without outliers')\n",
    "    ax3.axvline(y[col].mean(), color = 'r', linestyle = '--', label = 'Mean', linewidth = 1.2)\n",
    "    ax3.axvline(y[col].median(), color = 'g', linestyle = '--', label = 'Median', linewidth = 1.2)\n",
    "    ax3.axvline(y[col].mode()[0], color = 'b', linestyle = '--', label = 'Mode', linewidth = 1.2); ax3.legend(loc = 'best')\n",
    "    \n",
    "    kwargs = {'fontsize':14, 'color':'blue'}\n",
    "    ax1.set_title(col + ' Boxplot Analysis', **kwargs)\n",
    "    ax1.set_xlabel('Box', **kwargs)\n",
    "    ax1.set_ylabel(col + ' Values', **kwargs)\n",
    "\n",
    "    return plt.show()\n",
    "\n",
    "num_features = ['']\n",
    "def find_outlier(df, num_features):\n",
    "    q25 = df[num_features].quantile(0.25)\n",
    "    q75 = df[num_features].quantile(0.75)\n",
    "    iqr = q75-q25 #Interquartile range\n",
    "    lower, upper  = q25-1.5*iqr, q75+1.5*iqr\n",
    "    outliers_df = df[(df[num_features] < lower) | (df[num_features] > upper)]\n",
    "    outliers_removed_df = df[(df[num_features] >= lower) & (df[num_features] <= upper)]\n",
    "    \n",
    "    print(' \\'{}\\': {} /{}'.format(\n",
    "        num_features, outliers_df.shape[0], outliers_removed_df.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#Importing the libraries\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from scipy import stats; from scipy.stats import zscore, norm, randint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style; style.use('fivethirtyeight')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "5       8  113755.78              2          1               0   \n",
       "6       7       0.00              2          1               1   \n",
       "7       4  115046.74              4          1               0   \n",
       "8       4  142051.07              2          0               1   \n",
       "9       2  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the dataset\n",
    "dataset = pd.read_csv('bank.csv')\n",
    "dataset.columns\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No null values present in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distinguish the features and target variable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information of each client were key factors in determining the outcome, which is the dependent variable if the client is likely to stay or leave the bank. The ANN model outputs whether a particular client is likely to stay or leave the bank based on its independent variables, as it outputs either a 1 or 0. The number 1 is outputted if the client is classified as high risk of leaving the bank, and in contrary, a 0 is outputted if the client is likely to stay with the bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='Exited'\n",
    "non_features=[target]\n",
    "cat_features = list(dataset.select_dtypes(include=['object']))\n",
    "num_features=[col for col in dataset.select_dtypes(np.number).columns if col not in non_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'RowNumber': 0 /10000\n",
      " 'CustomerId': 0 /10000\n",
      " 'CreditScore': 15 /9985\n",
      " 'Age': 359 /9641\n",
      " 'Tenure': 0 /10000\n",
      " 'Balance': 0 /10000\n",
      " 'NumOfProducts': 60 /9940\n",
      " 'HasCrCard': 0 /10000\n",
      " 'IsActiveMember': 0 /10000\n",
      " 'EstimatedSalary': 0 /10000\n"
     ]
    }
   ],
   "source": [
    "# Outliers vs No Outliers\n",
    "for feature in num_features:\n",
    "    find_outlier(dataset, feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I needed to identify the matrix of features which is essentially the indexes that is going to be included in the input layer of the artifical neural network. This is justified on which independent variables will have the most impact on the output. I used common logic in determining that independent variables such as 'customerId', 'Surname' and 'RowNumber' will have no impact on the dependent (output) variable. In this case, I used all the information in between columns 3-13 as my matrix of features.\n",
    "\n",
    "However, when the artificial neural network is being trained, it will be able to identify which variables actually have the most impact on the output from the matrix of features and will assign larger weights to those variables on the networks synapses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop off the unique columns RowNumber, CustomerID and also the Surname which do not add value for the analysis\n",
    "dataset1 = dataset.copy()\n",
    "dataset1.drop('RowNumber',axis=1,inplace=True)\n",
    "dataset1.drop('CustomerId',axis=1,inplace=True)\n",
    "dataset1.drop('Surname',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before discarding duplicates = 10000\n",
      "Number of rows after discarding duplicates = 10000\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows (not removing the duplicates) /* There is no duplicates*/\n",
    "print('Number of rows before discarding duplicates = %d' % (dataset.shape[0]))\n",
    "dataset1.drop_duplicates(subset = None, keep = 'first', inplace=True)\n",
    "print('Number of rows after discarding duplicates = %d' % (dataset1.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CreditScore - Data ranges between 350 to 850, while 25th and 75th percentile is spread between 584.0 to 718.0. Median 652.0 is more than than Mean 650.53 which means cement is Fairly Symmetrical (Left). Column has HasOutliers.\n",
      "\n",
      "Age - Data ranges between 18 to 92, while 25th and 75th percentile is spread between 32.0 to 44.0. Median 37.0 is less than than Mean 38.92 which means cement is Highly Skewed (Right). Column has HasOutliers.\n",
      "\n",
      "Tenure - Data ranges between 0 to 10, while 25th and 75th percentile is spread between 3.0 to 7.0. Median 5.0 is less than than Mean 5.01 which means cement is Fairly Symmetrical (Right). Column has NoOutliers.\n",
      "\n",
      "Balance - Data ranges between 0.0 to 250898.09, while 25th and 75th percentile is spread between 0.0 to 127644.24. Median 97198.54 is more than than Mean 76485.89 which means cement is Fairly Symmetrical (Left). Column has NoOutliers.\n",
      "\n",
      "NumOfProducts - Data ranges between 1 to 4, while 25th and 75th percentile is spread between 1.0 to 2.0. Median 1.0 is less than than Mean 1.53 which means cement is Moderately Skewed (Right). Column has HasOutliers.\n",
      "\n",
      "HasCrCard - Data ranges between 0 to 1, while 25th and 75th percentile is spread between 0.0 to 1.0. Median 1.0 is more than than Mean 0.71 which means cement is Moderately Skewed (Left). Column has NoOutliers.\n",
      "\n",
      "IsActiveMember - Data ranges between 0 to 1, while 25th and 75th percentile is spread between 0.0 to 1.0. Median 1.0 is more than than Mean 0.52 which means cement is Fairly Symmetrical (Left). Column has NoOutliers.\n",
      "\n",
      "EstimatedSalary - Data ranges between 11.58 to 199992.48, while 25th and 75th percentile is spread between 51002.11 to 149388.25. Median 100193.92 is more than than Mean 100090.24 which means cement is Fairly Symmetrical (Left). Column has NoOutliers.\n",
      "\n",
      "Exited - Data ranges between 0 to 1, while 25th and 75th percentile is spread between 0.0 to 0.0. Median 0.0 is less than than Mean 0.2 which means cement is Highly Skewed (Right). Column has HasOutliers.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>650.53</td>\n",
       "      <td>38.92</td>\n",
       "      <td>5.01</td>\n",
       "      <td>76485.9</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.52</td>\n",
       "      <td>100090</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StdDev</th>\n",
       "      <td>96.65</td>\n",
       "      <td>10.49</td>\n",
       "      <td>2.89</td>\n",
       "      <td>62397.4</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.5</td>\n",
       "      <td>57510.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variance</th>\n",
       "      <td>9341.86</td>\n",
       "      <td>109.99</td>\n",
       "      <td>8.36</td>\n",
       "      <td>3.89344e+09</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.30746e+09</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minimum</th>\n",
       "      <td>350</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1</th>\n",
       "      <td>584</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51002.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median</th>\n",
       "      <td>652</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>97198.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3</th>\n",
       "      <td>718</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>127644</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>149388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maximum</th>\n",
       "      <td>850</td>\n",
       "      <td>92</td>\n",
       "      <td>10</td>\n",
       "      <td>250898</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>199992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Range</th>\n",
       "      <td>500</td>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>250898</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>199981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IQR</th>\n",
       "      <td>134</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>127644</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>98386.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>-0.43</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skewness</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanAbsDev</th>\n",
       "      <td>78.38</td>\n",
       "      <td>7.94</td>\n",
       "      <td>2.49</td>\n",
       "      <td>56660.7</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.5</td>\n",
       "      <td>49676.5</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkewnessComment</th>\n",
       "      <td>Fairly Symmetrical (Left)</td>\n",
       "      <td>Highly Skewed (Right)</td>\n",
       "      <td>Fairly Symmetrical (Right)</td>\n",
       "      <td>Fairly Symmetrical (Left)</td>\n",
       "      <td>Moderately Skewed (Right)</td>\n",
       "      <td>Moderately Skewed (Left)</td>\n",
       "      <td>Fairly Symmetrical (Left)</td>\n",
       "      <td>Fairly Symmetrical (Left)</td>\n",
       "      <td>Highly Skewed (Right)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OutliersComment</th>\n",
       "      <td>HasOutliers</td>\n",
       "      <td>HasOutliers</td>\n",
       "      <td>NoOutliers</td>\n",
       "      <td>NoOutliers</td>\n",
       "      <td>HasOutliers</td>\n",
       "      <td>NoOutliers</td>\n",
       "      <td>NoOutliers</td>\n",
       "      <td>NoOutliers</td>\n",
       "      <td>HasOutliers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               CreditScore                    Age  \\\n",
       "Count                                10000                  10000   \n",
       "Type                                 int64                  int64   \n",
       "Mean                                650.53                  38.92   \n",
       "StdDev                               96.65                  10.49   \n",
       "Variance                           9341.86                 109.99   \n",
       "Minimum                                350                     18   \n",
       "Q1                                     584                     32   \n",
       "Median                                 652                     37   \n",
       "Q3                                     718                     44   \n",
       "Maximum                                850                     92   \n",
       "Range                                  500                     74   \n",
       "IQR                                    134                     12   \n",
       "Kurtosis                             -0.43                    1.4   \n",
       "Skewness                             -0.07                   1.01   \n",
       "MeanAbsDev                           78.38                   7.94   \n",
       "SkewnessComment  Fairly Symmetrical (Left)  Highly Skewed (Right)   \n",
       "OutliersComment                HasOutliers            HasOutliers   \n",
       "\n",
       "                                     Tenure                    Balance  \\\n",
       "Count                                 10000                      10000   \n",
       "Type                                  int64                    float64   \n",
       "Mean                                   5.01                    76485.9   \n",
       "StdDev                                 2.89                    62397.4   \n",
       "Variance                               8.36                3.89344e+09   \n",
       "Minimum                                   0                          0   \n",
       "Q1                                        3                          0   \n",
       "Median                                    5                    97198.5   \n",
       "Q3                                        7                     127644   \n",
       "Maximum                                  10                     250898   \n",
       "Range                                    10                     250898   \n",
       "IQR                                       4                     127644   \n",
       "Kurtosis                              -1.17                      -1.49   \n",
       "Skewness                               0.01                      -0.14   \n",
       "MeanAbsDev                             2.49                    56660.7   \n",
       "SkewnessComment  Fairly Symmetrical (Right)  Fairly Symmetrical (Left)   \n",
       "OutliersComment                  NoOutliers                 NoOutliers   \n",
       "\n",
       "                             NumOfProducts                 HasCrCard  \\\n",
       "Count                                10000                     10000   \n",
       "Type                                 int64                     int64   \n",
       "Mean                                  1.53                      0.71   \n",
       "StdDev                                0.58                      0.46   \n",
       "Variance                              0.34                      0.21   \n",
       "Minimum                                  1                         0   \n",
       "Q1                                       1                         0   \n",
       "Median                                   1                         1   \n",
       "Q3                                       2                         1   \n",
       "Maximum                                  4                         1   \n",
       "Range                                    3                         1   \n",
       "IQR                                      1                         1   \n",
       "Kurtosis                              0.58                     -1.19   \n",
       "Skewness                              0.75                      -0.9   \n",
       "MeanAbsDev                            0.54                      0.42   \n",
       "SkewnessComment  Moderately Skewed (Right)  Moderately Skewed (Left)   \n",
       "OutliersComment                HasOutliers                NoOutliers   \n",
       "\n",
       "                            IsActiveMember            EstimatedSalary  \\\n",
       "Count                                10000                      10000   \n",
       "Type                                 int64                    float64   \n",
       "Mean                                  0.52                     100090   \n",
       "StdDev                                 0.5                    57510.5   \n",
       "Variance                              0.25                3.30746e+09   \n",
       "Minimum                                  0                      11.58   \n",
       "Q1                                       0                    51002.1   \n",
       "Median                                   1                     100194   \n",
       "Q3                                       1                     149388   \n",
       "Maximum                                  1                     199992   \n",
       "Range                                    1                     199981   \n",
       "IQR                                      1                    98386.1   \n",
       "Kurtosis                                -2                      -1.18   \n",
       "Skewness                             -0.06                          0   \n",
       "MeanAbsDev                             0.5                    49676.5   \n",
       "SkewnessComment  Fairly Symmetrical (Left)  Fairly Symmetrical (Left)   \n",
       "OutliersComment                 NoOutliers                 NoOutliers   \n",
       "\n",
       "                                Exited  \n",
       "Count                            10000  \n",
       "Type                             int64  \n",
       "Mean                               0.2  \n",
       "StdDev                             0.4  \n",
       "Variance                          0.16  \n",
       "Minimum                              0  \n",
       "Q1                                   0  \n",
       "Median                               0  \n",
       "Q3                                   0  \n",
       "Maximum                              1  \n",
       "Range                                1  \n",
       "IQR                                  0  \n",
       "Kurtosis                          0.17  \n",
       "Skewness                          1.47  \n",
       "MeanAbsDev                        0.32  \n",
       "SkewnessComment  Highly Skewed (Right)  \n",
       "OutliersComment            HasOutliers  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let us further analyze the descriptive statistics of the dataset (customzied)\n",
    "cdescribe(dataset1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on descriptive statistics, Age has got the Outliers and we will analyze further for normalizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Age', ylabel='Density'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of Age Group by Target Value\n",
    "sns.distplot(dataset1[dataset1.Exited == 1]['Age'], color = 'g')\n",
    "sns.distplot(dataset1[dataset1.Exited == 0]['Age'], color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking Outliers by Target column\n",
    "num_features=['Age']\n",
    "plt.figure(figsize=(20,10))\n",
    "for i,col in enumerate(num_features,start=1):\n",
    "    plt.subplot(3,3,i);\n",
    "    sns.boxplot(y=dataset1[col],x=dataset1['Exited']);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxplot, distribution of columns with and without outliers\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Age column \n",
      "Number of rows with outliers: 359\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>511</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1643.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>652</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>114675.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>670</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>177655.68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>646</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>97259.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>104719.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>510</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48071.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>656</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>153545.11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>186574.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9765</th>\n",
       "      <td>445</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>136770.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43678.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9832</th>\n",
       "      <td>595</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>105736.32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>89935.73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9894</th>\n",
       "      <td>521</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49054.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9936</th>\n",
       "      <td>609</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18708.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "58            511     Spain  Female   66       4       0.00              1   \n",
       "85            652     Spain  Female   75      10       0.00              2   \n",
       "104           670     Spain  Female   65       1       0.00              1   \n",
       "158           646    France  Female   73       6   97259.25              1   \n",
       "181           510    France    Male   65       2       0.00              2   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9753          656   Germany    Male   68       7  153545.11              1   \n",
       "9765          445    France    Male   64       2  136770.67              1   \n",
       "9832          595   Germany  Female   64       2  105736.32              1   \n",
       "9894          521    France  Female   77       6       0.00              2   \n",
       "9936          609    France    Male   77       1       0.00              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "58            1               0          1643.11       1  \n",
       "85            1               1        114675.75       0  \n",
       "104           1               1        177655.68       1  \n",
       "158           0               1        104719.66       0  \n",
       "181           1               1         48071.61       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9753          1               1        186574.68       0  \n",
       "9765          0               1         43678.06       0  \n",
       "9832          1               1         89935.73       1  \n",
       "9894          1               1         49054.10       0  \n",
       "9936          0               1         18708.76       0  \n",
       "\n",
       "[359 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\seaborn\\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Vertical\", \"x\"))\n",
      "C:\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2055: FutureWarning: The `axis` variable is no longer used and will be removed. Instead, assign variables directly to `x` or `y`.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2055: FutureWarning: The `axis` variable is no longer used and will be removed. Instead, assign variables directly to `x` or `y`.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Boxplot, distribution of columns with and without outliers'); print('--'*60)\n",
    "columns = ['Age']\n",
    "\n",
    "for i in columns:\n",
    "    Q3 = dataset1[i].quantile(0.75) \n",
    "    Q1 = dataset1[i].quantile(0.25)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    no_outlier = len(dataset1.loc[(dataset1[i] < (Q1 - 1.5 * IQR)) | (dataset1[i] > (Q3 + 1.5 * IQR))])\n",
    "    print(f'{i.capitalize()} column \\nNumber of rows with outliers: {no_outlier}')\n",
    "    \n",
    "    # print the outlier rows\n",
    "    if (no_outlier > 0):\n",
    "        display(dataset1.loc[(dataset1[i] < (Q1 - 1.5 * IQR)) | (dataset1[i] > (Q3 + 1.5 * IQR))].head(no_outlier)) \n",
    "    bdplots(dataset1, i)\n",
    "\n",
    "del i, Q1, Q3, IQR, columns, no_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "withOutliers = ['Age']    \n",
    " \n",
    "iqr   = dataset1[withOutliers].describe().T['75%']-dataset1[withOutliers].describe().T['25%']\n",
    "q1    = dataset1[withOutliers].describe().T['25%']-(iqr*1.5)\n",
    "q3    = dataset1[withOutliers].describe().T['75%']+(iqr*1.5)\n",
    "\n",
    "for i in withOutliers:\n",
    "    dataset1[i][dataset1[i]>q3[i]]=q3[i]\n",
    "    dataset1[i][dataset1[i]<q1[i]]=q1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking Outliers by Target column\n",
    "num_features=['Age']\n",
    "plt.figure(figsize=(20,10))\n",
    "for i,col in enumerate(num_features,start=1):\n",
    "    plt.subplot(3,3,i);\n",
    "    sns.boxplot(y=dataset1[col],x=dataset1['Exited']);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0             1               1        101348.88  \n",
       "1             0               1        112542.58  \n",
       "2             1               0        113931.57  \n",
       "3             0               0         93826.63  \n",
       "4             1               1         79084.10  \n",
       "...         ...             ...              ...  \n",
       "9995          1               0         96270.64  \n",
       "9996          1               1        101699.77  \n",
       "9997          0               1         42085.58  \n",
       "9998          1               0         92888.52  \n",
       "9999          1               0         38190.78  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#segregate input and output variables \n",
    "\n",
    "X = dataset1.iloc[:,:10]\n",
    "y = dataset1.iloc[:,10]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding: Dataaset contains tow categorical variables 'GENDER' and 'GEOGRAPHY'. Categories values are of string datatype and are an essential feature in model training, so using one-hot encoding values are being transformed into numerial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France' 'Spain' 'Germany']\n"
     ]
    }
   ],
   "source": [
    "print(X['Geography'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "print(X['Gender'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "0               1        101348.88                  0                0   \n",
       "1               1        112542.58                  0                1   \n",
       "2               0        113931.57                  0                0   \n",
       "3               0         93826.63                  0                0   \n",
       "4               1         79084.10                  0                1   \n",
       "\n",
       "   Gender_Male  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert X & Y variable to a categorical variable as relevant\n",
    "\n",
    "X['Geography'] = X['Geography'].astype('category')\n",
    "X['Gender'] = X['Gender'].astype('category')\n",
    "    \n",
    "X['Geography'] = X['Geography'].replace({1: 'France', 2: 'Germany', 3: 'Spain'})\n",
    "X['Gender'] = X['Gender'].replace({0:'Male', 1: 'Female'}) \n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the data set into training and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 11) (2000, 11) (8000,) (2000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize train/test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling: It's a technique perform to standardize the independent input features. Feature scaling is done to avoid the dominance of one feature over the other and is useful in avoiding hte prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train and X_test are now scaled and will be used to train and test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize & build the model. Identify the points of improvement and implement the same the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our Artificial Neural Network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import Keras Library and packages\n",
    "import keras\n",
    "import sys\n",
    "from keras.models import Sequential #to initialize NN\n",
    "from keras.layers import Dense #used to create layers in NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly initialize with the weights with small numbers close to zero but not zero. \n",
    "\n",
    "    \n",
    "Distribute features of the first observation, from our dataset, per each node in the input layer. Thus, eleven independent variables will be added to our input layer.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the ANN - Defining as a sequence of layers or a Graph \n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the input layer\n",
    "* units - number of nodes to add to the hidden layer. units should be the average of nodes in the input layer (11 nodes) and the number of nodes in the output layer (1 node), for this case is 11+1/2 = 6\n",
    "\n",
    "* Kernal_initializer - randomly initialize the weight with small numbers close to zero, according to uniform distribution.\n",
    "\n",
    "* activation - Activation function.\n",
    "\n",
    "* input_dim - number of nodes in the input layer, that our hidden layer should be expective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input layer\n",
    "classifier.add(Dense(units=6,kernel_initializer = 'uniform', activation='relu',input_dim=11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forward-Propagation: From the input to the output the neurons are activated, and the impact they have in the predicted results is measured by the assigned wieghts. Depending on the number of hidden layers, the system propagates the activation until getting the predicted result y.\n",
    "        \n",
    "- To define the first hidden layer, we firstly will have to define an activation function. The best one is the Rectifier Function and we'll choose this one for the hidden layers. Further more also by using a Sigmoid function to the output layer will allow us to calculate the probabilities of the different class(leaving or staying the bank). In the end, we will be able to rand the customers by their probability to leave the bank.\n",
    "\n",
    "Adding Second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=6,kernel_initializer='uniform',activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Output Layer\n",
    "- units - one node in the output layer\n",
    "- activation - if there are more than two categories in the output we would use the softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=1,kernel_initializer='uniform',activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cost Function: Meausre the generated error by comparing the predicted value with the true value.\n",
    "\n",
    "- Compiling the ANN\n",
    "\n",
    "- optimizer - algorithm to use to find the best weights that will make our system powerful.\n",
    "\n",
    "- loss - Loss function within our optimizer algorithm\n",
    "\n",
    "- metric - criteria to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "classifier.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/100\n",
      "6400/6400 [==============================] - 1s 110us/step - loss: 0.4888 - accuracy: 0.7953 - val_loss: 0.4387 - val_accuracy: 0.7969\n",
      "Epoch 2/100\n",
      "6400/6400 [==============================] - 1s 89us/step - loss: 0.4295 - accuracy: 0.7958 - val_loss: 0.4324 - val_accuracy: 0.7969\n",
      "Epoch 3/100\n",
      "6400/6400 [==============================] - 1s 90us/step - loss: 0.4259 - accuracy: 0.7958 - val_loss: 0.4281 - val_accuracy: 0.7969\n",
      "Epoch 4/100\n",
      "6400/6400 [==============================] - 1s 89us/step - loss: 0.4224 - accuracy: 0.7958 - val_loss: 0.4241 - val_accuracy: 0.7969\n",
      "Epoch 5/100\n",
      "6400/6400 [==============================] - 1s 90us/step - loss: 0.4197 - accuracy: 0.8155 - val_loss: 0.4216 - val_accuracy: 0.8269\n",
      "Epoch 6/100\n",
      "6400/6400 [==============================] - 1s 90us/step - loss: 0.4170 - accuracy: 0.8263 - val_loss: 0.4198 - val_accuracy: 0.8244\n",
      "Epoch 7/100\n",
      "6400/6400 [==============================] - 1s 91us/step - loss: 0.4158 - accuracy: 0.8277 - val_loss: 0.4191 - val_accuracy: 0.8269\n",
      "Epoch 8/100\n",
      "6400/6400 [==============================] - 1s 90us/step - loss: 0.4142 - accuracy: 0.8289 - val_loss: 0.4190 - val_accuracy: 0.8263\n",
      "Epoch 9/100\n",
      "6400/6400 [==============================] - 1s 97us/step - loss: 0.4132 - accuracy: 0.8319 - val_loss: 0.4178 - val_accuracy: 0.8269\n",
      "Epoch 10/100\n",
      "6400/6400 [==============================] - 1s 91us/step - loss: 0.4123 - accuracy: 0.8333 - val_loss: 0.4169 - val_accuracy: 0.8288\n",
      "Epoch 11/100\n",
      "6400/6400 [==============================] - 1s 90us/step - loss: 0.4117 - accuracy: 0.8333 - val_loss: 0.4161 - val_accuracy: 0.8263\n",
      "Epoch 12/100\n",
      "6400/6400 [==============================] - 1s 93us/step - loss: 0.4106 - accuracy: 0.8341 - val_loss: 0.4155 - val_accuracy: 0.8269\n",
      "Epoch 13/100\n",
      "6400/6400 [==============================] - 1s 91us/step - loss: 0.4102 - accuracy: 0.8330 - val_loss: 0.4147 - val_accuracy: 0.8263\n",
      "Epoch 14/100\n",
      "6400/6400 [==============================] - 1s 92us/step - loss: 0.4097 - accuracy: 0.8333 - val_loss: 0.4143 - val_accuracy: 0.8294\n",
      "Epoch 15/100\n",
      "6400/6400 [==============================] - 1s 92us/step - loss: 0.4087 - accuracy: 0.8333 - val_loss: 0.4143 - val_accuracy: 0.8269\n",
      "Epoch 16/100\n",
      "6400/6400 [==============================] - 1s 90us/step - loss: 0.4086 - accuracy: 0.8338 - val_loss: 0.4137 - val_accuracy: 0.8294\n",
      "Epoch 17/100\n",
      "6400/6400 [==============================] - 1s 97us/step - loss: 0.4078 - accuracy: 0.8338 - val_loss: 0.4136 - val_accuracy: 0.8294\n",
      "Epoch 18/100\n",
      "6400/6400 [==============================] - 1s 92us/step - loss: 0.4074 - accuracy: 0.8352 - val_loss: 0.4132 - val_accuracy: 0.8275\n",
      "Epoch 19/100\n",
      "6400/6400 [==============================] - 1s 94us/step - loss: 0.4074 - accuracy: 0.8350 - val_loss: 0.4123 - val_accuracy: 0.8288\n",
      "Epoch 20/100\n",
      "6400/6400 [==============================] - 1s 91us/step - loss: 0.4067 - accuracy: 0.8350 - val_loss: 0.4123 - val_accuracy: 0.8294\n",
      "Epoch 21/100\n",
      "6400/6400 [==============================] - 1s 91us/step - loss: 0.4064 - accuracy: 0.8364 - val_loss: 0.4124 - val_accuracy: 0.8288\n",
      "Epoch 22/100\n",
      "6400/6400 [==============================] - 1s 91us/step - loss: 0.4062 - accuracy: 0.8345 - val_loss: 0.4124 - val_accuracy: 0.8275\n",
      "Epoch 23/100\n",
      "6400/6400 [==============================] - 1s 91us/step - loss: 0.4055 - accuracy: 0.8353 - val_loss: 0.4148 - val_accuracy: 0.8288\n",
      "Epoch 24/100\n",
      "6400/6400 [==============================] - 1s 91us/step - loss: 0.4059 - accuracy: 0.8369 - val_loss: 0.4124 - val_accuracy: 0.8263\n",
      "Epoch 25/100\n",
      "6400/6400 [==============================] - 1s 90us/step - loss: 0.4059 - accuracy: 0.8348 - val_loss: 0.4116 - val_accuracy: 0.8306\n",
      "Epoch 26/100\n",
      "6400/6400 [==============================] - 1s 98us/step - loss: 0.4052 - accuracy: 0.8356 - val_loss: 0.4112 - val_accuracy: 0.8294\n",
      "Epoch 27/100\n",
      "6400/6400 [==============================] - 1s 94us/step - loss: 0.4052 - accuracy: 0.8358 - val_loss: 0.4121 - val_accuracy: 0.8300\n",
      "Epoch 28/100\n",
      "6400/6400 [==============================] - 1s 91us/step - loss: 0.4047 - accuracy: 0.8361 - val_loss: 0.4117 - val_accuracy: 0.8256\n",
      "Epoch 29/100\n",
      "6400/6400 [==============================] - 1s 91us/step - loss: 0.4049 - accuracy: 0.8355 - val_loss: 0.4104 - val_accuracy: 0.8325\n",
      "Epoch 30/100\n",
      "6400/6400 [==============================] - 1s 91us/step - loss: 0.4042 - accuracy: 0.8353 - val_loss: 0.4108 - val_accuracy: 0.8306\n",
      "Epoch 31/100\n",
      "6400/6400 [==============================] - 1s 91us/step - loss: 0.4047 - accuracy: 0.8353 - val_loss: 0.4105 - val_accuracy: 0.8275\n",
      "Epoch 32/100\n",
      "6400/6400 [==============================] - 1s 91us/step - loss: 0.4047 - accuracy: 0.8356 - val_loss: 0.4111 - val_accuracy: 0.8281\n",
      "Epoch 33/100\n",
      "6400/6400 [==============================] - 1s 91us/step - loss: 0.4044 - accuracy: 0.8352 - val_loss: 0.4112 - val_accuracy: 0.8269\n",
      "Epoch 34/100\n",
      "6400/6400 [==============================] - 1s 91us/step - loss: 0.4041 - accuracy: 0.8345 - val_loss: 0.4117 - val_accuracy: 0.8288\n",
      "Epoch 35/100\n",
      "6400/6400 [==============================] - 1s 96us/step - loss: 0.4040 - accuracy: 0.8352 - val_loss: 0.4103 - val_accuracy: 0.8325\n",
      "Epoch 36/100\n",
      "6400/6400 [==============================] - 1s 89us/step - loss: 0.4043 - accuracy: 0.8353 - val_loss: 0.4106 - val_accuracy: 0.8288\n",
      "Epoch 37/100\n",
      "6400/6400 [==============================] - 1s 93us/step - loss: 0.4043 - accuracy: 0.8355 - val_loss: 0.4102 - val_accuracy: 0.8288\n",
      "Epoch 38/100\n",
      "6400/6400 [==============================] - 1s 92us/step - loss: 0.4038 - accuracy: 0.8356 - val_loss: 0.4106 - val_accuracy: 0.8319\n",
      "Epoch 39/100\n",
      "6400/6400 [==============================] - 1s 99us/step - loss: 0.4037 - accuracy: 0.8350 - val_loss: 0.4119 - val_accuracy: 0.8319\n",
      "Epoch 40/100\n",
      "6400/6400 [==============================] - 1s 94us/step - loss: 0.4038 - accuracy: 0.8372 - val_loss: 0.4111 - val_accuracy: 0.8319\n",
      "Epoch 41/100\n",
      "6400/6400 [==============================] - 1s 98us/step - loss: 0.4034 - accuracy: 0.8366 - val_loss: 0.4102 - val_accuracy: 0.8300\n",
      "Epoch 42/100\n",
      "6400/6400 [==============================] - 1s 99us/step - loss: 0.4037 - accuracy: 0.8358 - val_loss: 0.4103 - val_accuracy: 0.8313\n",
      "Epoch 43/100\n",
      "6400/6400 [==============================] - 1s 96us/step - loss: 0.4036 - accuracy: 0.8353 - val_loss: 0.4102 - val_accuracy: 0.8313\n",
      "Epoch 44/100\n",
      "6400/6400 [==============================] - 1s 93us/step - loss: 0.4035 - accuracy: 0.8369 - val_loss: 0.4095 - val_accuracy: 0.8281\n",
      "Epoch 45/100\n",
      "6400/6400 [==============================] - 1s 109us/step - loss: 0.4033 - accuracy: 0.8342 - val_loss: 0.4105 - val_accuracy: 0.8288\n",
      "Epoch 46/100\n",
      "6400/6400 [==============================] - 1s 105us/step - loss: 0.4033 - accuracy: 0.8359 - val_loss: 0.4103 - val_accuracy: 0.8269\n",
      "Epoch 47/100\n",
      "6400/6400 [==============================] - 1s 105us/step - loss: 0.4033 - accuracy: 0.8338 - val_loss: 0.4095 - val_accuracy: 0.8281\n",
      "Epoch 48/100\n",
      "6400/6400 [==============================] - 1s 110us/step - loss: 0.4029 - accuracy: 0.8334 - val_loss: 0.4108 - val_accuracy: 0.8306\n",
      "Epoch 49/100\n",
      "6400/6400 [==============================] - 1s 108us/step - loss: 0.4031 - accuracy: 0.8352 - val_loss: 0.4100 - val_accuracy: 0.8281\n",
      "Epoch 50/100\n",
      "6400/6400 [==============================] - 1s 103us/step - loss: 0.4023 - accuracy: 0.8352 - val_loss: 0.4108 - val_accuracy: 0.8319\n",
      "Epoch 51/100\n",
      "6400/6400 [==============================] - 1s 103us/step - loss: 0.4036 - accuracy: 0.8338 - val_loss: 0.4098 - val_accuracy: 0.8269\n",
      "Epoch 52/100\n",
      "6400/6400 [==============================] - 1s 103us/step - loss: 0.4027 - accuracy: 0.8348 - val_loss: 0.4092 - val_accuracy: 0.8288\n",
      "Epoch 53/100\n",
      "6400/6400 [==============================] - 1s 103us/step - loss: 0.4029 - accuracy: 0.8361 - val_loss: 0.4093 - val_accuracy: 0.8294\n",
      "Epoch 54/100\n",
      "6400/6400 [==============================] - 1s 104us/step - loss: 0.4028 - accuracy: 0.8342 - val_loss: 0.4124 - val_accuracy: 0.8275\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 1s 100us/step - loss: 0.4027 - accuracy: 0.8350 - val_loss: 0.4115 - val_accuracy: 0.8300\n",
      "Epoch 56/100\n",
      "6400/6400 [==============================] - 1s 114us/step - loss: 0.4029 - accuracy: 0.8356 - val_loss: 0.4097 - val_accuracy: 0.8269\n",
      "Epoch 57/100\n",
      "6400/6400 [==============================] - 1s 102us/step - loss: 0.4026 - accuracy: 0.8338 - val_loss: 0.4096 - val_accuracy: 0.8300\n",
      "Epoch 58/100\n",
      "6400/6400 [==============================] - 1s 101us/step - loss: 0.4026 - accuracy: 0.8355 - val_loss: 0.4098 - val_accuracy: 0.8325\n",
      "Epoch 59/100\n",
      "6400/6400 [==============================] - 1s 104us/step - loss: 0.4029 - accuracy: 0.8356 - val_loss: 0.4091 - val_accuracy: 0.8294\n",
      "Epoch 60/100\n",
      "6400/6400 [==============================] - 1s 103us/step - loss: 0.4026 - accuracy: 0.8345 - val_loss: 0.4106 - val_accuracy: 0.8294\n",
      "Epoch 61/100\n",
      "6400/6400 [==============================] - 1s 100us/step - loss: 0.4030 - accuracy: 0.8363 - val_loss: 0.4094 - val_accuracy: 0.8288\n",
      "Epoch 62/100\n",
      "6400/6400 [==============================] - 1s 104us/step - loss: 0.4025 - accuracy: 0.8373 - val_loss: 0.4088 - val_accuracy: 0.8300\n",
      "Epoch 63/100\n",
      "6400/6400 [==============================] - 1s 102us/step - loss: 0.4026 - accuracy: 0.8341 - val_loss: 0.4105 - val_accuracy: 0.8275\n",
      "Epoch 64/100\n",
      "6400/6400 [==============================] - 1s 106us/step - loss: 0.4022 - accuracy: 0.8347 - val_loss: 0.4088 - val_accuracy: 0.8288\n",
      "Epoch 65/100\n",
      "6400/6400 [==============================] - 1s 104us/step - loss: 0.4025 - accuracy: 0.8366 - val_loss: 0.4091 - val_accuracy: 0.8306\n",
      "Epoch 66/100\n",
      "6400/6400 [==============================] - 1s 106us/step - loss: 0.4030 - accuracy: 0.8367 - val_loss: 0.4088 - val_accuracy: 0.8294\n",
      "Epoch 67/100\n",
      "6400/6400 [==============================] - 1s 107us/step - loss: 0.4024 - accuracy: 0.8361 - val_loss: 0.4092 - val_accuracy: 0.8288\n",
      "Epoch 68/100\n",
      "6400/6400 [==============================] - 1s 104us/step - loss: 0.4025 - accuracy: 0.8353 - val_loss: 0.4092 - val_accuracy: 0.8288\n",
      "Epoch 69/100\n",
      "6400/6400 [==============================] - 1s 103us/step - loss: 0.4025 - accuracy: 0.8345 - val_loss: 0.4094 - val_accuracy: 0.8281\n",
      "Epoch 70/100\n",
      "6400/6400 [==============================] - 1s 104us/step - loss: 0.4019 - accuracy: 0.8363 - val_loss: 0.4081 - val_accuracy: 0.8294\n",
      "Epoch 71/100\n",
      "6400/6400 [==============================] - 1s 102us/step - loss: 0.4023 - accuracy: 0.8366 - val_loss: 0.4088 - val_accuracy: 0.8281\n",
      "Epoch 72/100\n",
      "6400/6400 [==============================] - 1s 101us/step - loss: 0.4022 - accuracy: 0.8348 - val_loss: 0.4088 - val_accuracy: 0.8306\n",
      "Epoch 73/100\n",
      "6400/6400 [==============================] - 1s 103us/step - loss: 0.4023 - accuracy: 0.8352 - val_loss: 0.4092 - val_accuracy: 0.8306\n",
      "Epoch 74/100\n",
      "6400/6400 [==============================] - 1s 101us/step - loss: 0.4023 - accuracy: 0.8353 - val_loss: 0.4088 - val_accuracy: 0.8294\n",
      "Epoch 75/100\n",
      "6400/6400 [==============================] - 1s 105us/step - loss: 0.4023 - accuracy: 0.8352 - val_loss: 0.4084 - val_accuracy: 0.8288\n",
      "Epoch 76/100\n",
      "6400/6400 [==============================] - 1s 103us/step - loss: 0.4025 - accuracy: 0.8348 - val_loss: 0.4083 - val_accuracy: 0.8300\n",
      "Epoch 77/100\n",
      "6400/6400 [==============================] - 1s 102us/step - loss: 0.4024 - accuracy: 0.8358 - val_loss: 0.4082 - val_accuracy: 0.8281\n",
      "Epoch 78/100\n",
      "6400/6400 [==============================] - 1s 105us/step - loss: 0.4025 - accuracy: 0.8373 - val_loss: 0.4086 - val_accuracy: 0.8275\n",
      "Epoch 79/100\n",
      "6400/6400 [==============================] - 1s 101us/step - loss: 0.4027 - accuracy: 0.8331 - val_loss: 0.4086 - val_accuracy: 0.8275\n",
      "Epoch 80/100\n",
      "6400/6400 [==============================] - 1s 99us/step - loss: 0.4025 - accuracy: 0.8358 - val_loss: 0.4080 - val_accuracy: 0.8288\n",
      "Epoch 81/100\n",
      "6400/6400 [==============================] - 1s 99us/step - loss: 0.4022 - accuracy: 0.8355 - val_loss: 0.4080 - val_accuracy: 0.8275\n",
      "Epoch 82/100\n",
      "6400/6400 [==============================] - 1s 98us/step - loss: 0.4020 - accuracy: 0.8359 - val_loss: 0.4086 - val_accuracy: 0.8294\n",
      "Epoch 83/100\n",
      "6400/6400 [==============================] - 1s 107us/step - loss: 0.4017 - accuracy: 0.8369 - val_loss: 0.4082 - val_accuracy: 0.8275\n",
      "Epoch 84/100\n",
      "6400/6400 [==============================] - 1s 100us/step - loss: 0.4022 - accuracy: 0.8341 - val_loss: 0.4086 - val_accuracy: 0.8288\n",
      "Epoch 85/100\n",
      "6400/6400 [==============================] - 1s 98us/step - loss: 0.4021 - accuracy: 0.8364 - val_loss: 0.4086 - val_accuracy: 0.8275\n",
      "Epoch 86/100\n",
      "6400/6400 [==============================] - 1s 99us/step - loss: 0.4020 - accuracy: 0.8359 - val_loss: 0.4086 - val_accuracy: 0.8300\n",
      "Epoch 87/100\n",
      "6400/6400 [==============================] - 1s 99us/step - loss: 0.4023 - accuracy: 0.8348 - val_loss: 0.4084 - val_accuracy: 0.8263\n",
      "Epoch 88/100\n",
      "6400/6400 [==============================] - 1s 98us/step - loss: 0.4024 - accuracy: 0.8358 - val_loss: 0.4083 - val_accuracy: 0.8288\n",
      "Epoch 89/100\n",
      "6400/6400 [==============================] - 1s 100us/step - loss: 0.4016 - accuracy: 0.8341 - val_loss: 0.4092 - val_accuracy: 0.8288\n",
      "Epoch 90/100\n",
      "6400/6400 [==============================] - 1s 100us/step - loss: 0.4023 - accuracy: 0.8348 - val_loss: 0.4085 - val_accuracy: 0.8281\n",
      "Epoch 91/100\n",
      "6400/6400 [==============================] - 1s 100us/step - loss: 0.4022 - accuracy: 0.8361 - val_loss: 0.4082 - val_accuracy: 0.8269\n",
      "Epoch 92/100\n",
      "6400/6400 [==============================] - 1s 98us/step - loss: 0.4016 - accuracy: 0.8372 - val_loss: 0.4083 - val_accuracy: 0.8288\n",
      "Epoch 93/100\n",
      "6400/6400 [==============================] - 1s 97us/step - loss: 0.4022 - accuracy: 0.8363 - val_loss: 0.4076 - val_accuracy: 0.8294\n",
      "Epoch 94/100\n",
      "6400/6400 [==============================] - 1s 101us/step - loss: 0.4017 - accuracy: 0.8352 - val_loss: 0.4086 - val_accuracy: 0.8288\n",
      "Epoch 95/100\n",
      "6400/6400 [==============================] - 1s 100us/step - loss: 0.4023 - accuracy: 0.8358 - val_loss: 0.4083 - val_accuracy: 0.8275\n",
      "Epoch 96/100\n",
      "6400/6400 [==============================] - 1s 98us/step - loss: 0.4018 - accuracy: 0.8355 - val_loss: 0.4101 - val_accuracy: 0.8294\n",
      "Epoch 97/100\n",
      "6400/6400 [==============================] - 1s 100us/step - loss: 0.4018 - accuracy: 0.8358 - val_loss: 0.4090 - val_accuracy: 0.8319\n",
      "Epoch 98/100\n",
      "6400/6400 [==============================] - 1s 98us/step - loss: 0.4021 - accuracy: 0.8350 - val_loss: 0.4081 - val_accuracy: 0.8275\n",
      "Epoch 99/100\n",
      "6400/6400 [==============================] - 1s 98us/step - loss: 0.4021 - accuracy: 0.8344 - val_loss: 0.4078 - val_accuracy: 0.8288\n",
      "Epoch 100/100\n",
      "6400/6400 [==============================] - 1s 99us/step - loss: 0.4016 - accuracy: 0.8347 - val_loss: 0.4082 - val_accuracy: 0.8331\n"
     ]
    }
   ],
   "source": [
    "#model is trained over 100 epochs\n",
    "model = classifier.fit(X_train,y_train,validation_split=0.2,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our trained ANN model which, after running 100 epochs on the training set, returned an accuracy of around 83.3%\n",
    "\n",
    "As we can see with the 100th EPOCH loss is minimized and the accuracy has increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Model Score / Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Predictions\n",
    "\n",
    "We've trained our ANN model and now we're ready to see its capability on predicting future churn results with our test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the Test set results\n",
    "If the test set that the deep neural network has not been trained on, gets the same percentage of accuracy of 84% as the training set before, it validates that our model has a high accuracy and is stable.\n",
    "\n",
    "I implemented the classifier predict method so the DNN could predict all the probabilities that the 2000 customers of the test set would leave the bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, I needed to also implement a threshold to get results for which customers were the highest risk. This is why I inputted a threshold of 0.5 to get me this result. If the predicted probability was above 0.5 the DNN outputted a True and if it was below the DNN outputted a False. This means that any customer having a predicted probability above 0.5 was a high risk of leaving the bank, and vice versa anything below was not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7975\n"
     ]
    }
   ],
   "source": [
    "# Prediction variable\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Model score calculation\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred.astype('int'),y_test.astype('int'))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the Test set results at 0.5 Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting the Test set results \n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Threshold of \n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our model the first five customer will not leave the bank while the sixth on the rank will.\n",
    "Again the next three customer will not leave and the tenth customer ont the rank will and so on...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for one new example\n",
    "Geography: France\n",
    "Credit Score: 600\n",
    "Tenure: 3\n",
    "Gender: Male\n",
    "Age: 40\n",
    "Balance: 60000\n",
    "Number of Products: 2\n",
    "Has Credit Card: Yes\n",
    "Is Active Member: Yes\n",
    "Estimated Salary: 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rec = sc.transform(np.array([[0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]]))\n",
    "new_pred = classifier.predict(new_rec)\n",
    "new_pred = (new_pred > 0.5)\n",
    "new_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer - adam\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = 3)                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[For optimizer: adam] mean: 0.8446250021457672  variance: 0.021643787333396194\n"
     ]
    }
   ],
   "source": [
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"[For optimizer: adam]\",\"mean:\",mean,\" variance:\",variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer - rmsprop\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = 3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[For optimizer: rmsprop] mean: 0.8465000033378601  variance: 0.01626730074207485\n"
     ]
    }
   ],
   "source": [
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"[For optimizer: rmsprop]\",\"mean:\",mean,\" variance:\",variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the ANN(Dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since rmsprop is having higher accuracy mean, we shall consider rmsprop in our further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 0.5002 - accuracy: 0.7958\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4399 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4341 - accuracy: 0.7960\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4307 - accuracy: 0.7960\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4290 - accuracy: 0.7960\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4281 - accuracy: 0.8071\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4275 - accuracy: 0.8202\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4285 - accuracy: 0.8241\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.4289 - accuracy: 0.8278\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.4282 - accuracy: 0.8234\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4283 - accuracy: 0.8269\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.4283 - accuracy: 0.8257\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4273 - accuracy: 0.8261\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4286 - accuracy: 0.8270\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.4268 - accuracy: 0.8295\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4291 - accuracy: 0.8270\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.4260 - accuracy: 0.8278\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4249 - accuracy: 0.8311\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4257 - accuracy: 0.8281\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4265 - accuracy: 0.8288\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4237 - accuracy: 0.8294\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4242 - accuracy: 0.8315\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4233 - accuracy: 0.8320\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.4276 - accuracy: 0.8316\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.4240 - accuracy: 0.8289\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4248 - accuracy: 0.8315\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4251 - accuracy: 0.8315\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.4263 - accuracy: 0.8309\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.4274 - accuracy: 0.8294\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.4280 - accuracy: 0.8299\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.4253 - accuracy: 0.8310\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.4270 - accuracy: 0.8299\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.4264 - accuracy: 0.8303\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.4262 - accuracy: 0.8304\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.4264 - accuracy: 0.8311\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4237 - accuracy: 0.8289\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.4256 - accuracy: 0.8307\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.4256 - accuracy: 0.8291\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.4274 - accuracy: 0.8305\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.4234 - accuracy: 0.8338\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.4268 - accuracy: 0.8305\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4264 - accuracy: 0.8286\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4254 - accuracy: 0.8313\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4257 - accuracy: 0.8310\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4259 - accuracy: 0.8330\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4258 - accuracy: 0.8303\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4255 - accuracy: 0.8311\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4261 - accuracy: 0.8304\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4269 - accuracy: 0.8316\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4254 - accuracy: 0.8314\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 0.4220 - accuracy: 0.8320\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 0.4269 - accuracy: 0.8298\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4232 - accuracy: 0.8300\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4265 - accuracy: 0.8331\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4221 - accuracy: 0.8313\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4235 - accuracy: 0.8307\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 0.4263 - accuracy: 0.8311\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4288 - accuracy: 0.8311\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4224 - accuracy: 0.8328\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4258 - accuracy: 0.8313\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4218 - accuracy: 0.8317\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4243 - accuracy: 0.8313\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4252 - accuracy: 0.8307\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4280 - accuracy: 0.8311\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 0.4253 - accuracy: 0.8317\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4249 - accuracy: 0.8301\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4238 - accuracy: 0.8316\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4248 - accuracy: 0.8289\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 0.4248 - accuracy: 0.8300\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4230 - accuracy: 0.8313\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4265 - accuracy: 0.8316\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4219 - accuracy: 0.8309\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 0.4237 - accuracy: 0.8311\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4225 - accuracy: 0.8304\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4261 - accuracy: 0.8325\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4242 - accuracy: 0.8296\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 0.4226 - accuracy: 0.8320\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4211 - accuracy: 0.8320\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.4218 - accuracy: 0.8299\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4239 - accuracy: 0.8295\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4257 - accuracy: 0.8273\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4232 - accuracy: 0.8296\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4226 - accuracy: 0.8306\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4244 - accuracy: 0.8321\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4270 - accuracy: 0.8295\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4211 - accuracy: 0.8304\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4274 - accuracy: 0.8298\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4226 - accuracy: 0.8322\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4209 - accuracy: 0.8322\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4217 - accuracy: 0.8304\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4211 - accuracy: 0.8290\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.4234 - accuracy: 0.8309\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4233 - accuracy: 0.8321\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.4205 - accuracy: 0.8292\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4236 - accuracy: 0.8307\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4222 - accuracy: 0.8305\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4272 - accuracy: 0.8294\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4244 - accuracy: 0.8299\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4239 - accuracy: 0.8320\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.4252 - accuracy: 0.8305\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model = classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run with the below parameters and it was running very long..... to complate. \n",
    "parameters = {\n",
    "    'batch_size': [25, 32],\n",
    "    'epochs': [100, 500],\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "Based on the results, i have chosen the best parameter as batch_size: 25, epochs=500, optimizer = rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'batch_size': [25,32],\n",
    "    'epochs': [100,500],\n",
    "    'optimizer': ['adam','rmsprop']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = 'accuracy', cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6400/6400 [==============================] - 0s 55us/step - loss: 0.5744 - accuracy: 0.7977\n",
      "Epoch 2/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4344 - accuracy: 0.7980\n",
      "Epoch 3/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4286 - accuracy: 0.7980\n",
      "Epoch 4/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4257 - accuracy: 0.7980\n",
      "Epoch 5/100\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4231 - accuracy: 0.7980\n",
      "Epoch 6/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4211 - accuracy: 0.7980\n",
      "Epoch 7/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4192 - accuracy: 0.7980\n",
      "Epoch 8/100\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4178 - accuracy: 0.8166\n",
      "Epoch 9/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4167 - accuracy: 0.8219\n",
      "Epoch 10/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4157 - accuracy: 0.8239\n",
      "Epoch 11/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4149 - accuracy: 0.8256\n",
      "Epoch 12/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4139 - accuracy: 0.8277\n",
      "Epoch 13/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4135 - accuracy: 0.8291\n",
      "Epoch 14/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4126 - accuracy: 0.8289\n",
      "Epoch 15/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4122 - accuracy: 0.8308\n",
      "Epoch 16/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4112 - accuracy: 0.8325\n",
      "Epoch 17/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4113 - accuracy: 0.8311\n",
      "Epoch 18/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4106 - accuracy: 0.8317\n",
      "Epoch 19/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4101 - accuracy: 0.8327\n",
      "Epoch 20/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4097 - accuracy: 0.8323\n",
      "Epoch 21/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4094 - accuracy: 0.8325\n",
      "Epoch 22/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4090 - accuracy: 0.8317\n",
      "Epoch 23/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4087 - accuracy: 0.8309\n",
      "Epoch 24/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4083 - accuracy: 0.8323\n",
      "Epoch 25/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4079 - accuracy: 0.8320\n",
      "Epoch 26/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4078 - accuracy: 0.8334\n",
      "Epoch 27/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4077 - accuracy: 0.8325\n",
      "Epoch 28/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4073 - accuracy: 0.8308\n",
      "Epoch 29/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4072 - accuracy: 0.8331\n",
      "Epoch 30/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4071 - accuracy: 0.8336\n",
      "Epoch 31/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4065 - accuracy: 0.8331\n",
      "Epoch 32/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4064 - accuracy: 0.8345\n",
      "Epoch 33/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4064 - accuracy: 0.8341\n",
      "Epoch 34/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4060 - accuracy: 0.8334\n",
      "Epoch 35/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4058 - accuracy: 0.8338\n",
      "Epoch 36/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4057 - accuracy: 0.8341\n",
      "Epoch 37/100\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4053 - accuracy: 0.8342\n",
      "Epoch 38/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4053 - accuracy: 0.8331\n",
      "Epoch 39/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4051 - accuracy: 0.8353\n",
      "Epoch 40/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4049 - accuracy: 0.8342\n",
      "Epoch 41/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4051 - accuracy: 0.8348\n",
      "Epoch 42/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4049 - accuracy: 0.8347\n",
      "Epoch 43/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4045 - accuracy: 0.8336\n",
      "Epoch 44/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4044 - accuracy: 0.8352\n",
      "Epoch 45/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4046 - accuracy: 0.8353\n",
      "Epoch 46/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4043 - accuracy: 0.8342\n",
      "Epoch 47/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4045 - accuracy: 0.8344\n",
      "Epoch 48/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4041 - accuracy: 0.8341\n",
      "Epoch 49/100\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4040 - accuracy: 0.8353\n",
      "Epoch 50/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4038 - accuracy: 0.8344\n",
      "Epoch 51/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4039 - accuracy: 0.8341\n",
      "Epoch 52/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4036 - accuracy: 0.8344\n",
      "Epoch 53/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4037 - accuracy: 0.8355\n",
      "Epoch 54/100\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4035 - accuracy: 0.8353\n",
      "Epoch 55/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4032 - accuracy: 0.8348\n",
      "Epoch 56/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4033 - accuracy: 0.8339\n",
      "Epoch 57/100\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4032 - accuracy: 0.8344\n",
      "Epoch 58/100\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4033 - accuracy: 0.8348\n",
      "Epoch 59/100\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4035 - accuracy: 0.8359\n",
      "Epoch 60/100\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4032 - accuracy: 0.8342\n",
      "Epoch 61/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4032 - accuracy: 0.8355\n",
      "Epoch 62/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4030 - accuracy: 0.8347\n",
      "Epoch 63/100\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4029 - accuracy: 0.8350\n",
      "Epoch 64/100\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4028 - accuracy: 0.8363\n",
      "Epoch 65/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4029 - accuracy: 0.8347\n",
      "Epoch 66/100\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4025 - accuracy: 0.8353\n",
      "Epoch 67/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4024 - accuracy: 0.8361\n",
      "Epoch 68/100\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4029 - accuracy: 0.8364\n",
      "Epoch 69/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4026 - accuracy: 0.8359\n",
      "Epoch 70/100\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4025 - accuracy: 0.8358\n",
      "Epoch 71/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4025 - accuracy: 0.8361\n",
      "Epoch 72/100\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4025 - accuracy: 0.8353\n",
      "Epoch 73/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4021 - accuracy: 0.8345\n",
      "Epoch 74/100\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4025 - accuracy: 0.8372\n",
      "Epoch 75/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4025 - accuracy: 0.8361\n",
      "Epoch 76/100\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4025 - accuracy: 0.8353\n",
      "Epoch 77/100\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4021 - accuracy: 0.8358\n",
      "Epoch 78/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4023 - accuracy: 0.8345\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4023 - accuracy: 0.8358\n",
      "Epoch 80/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4019 - accuracy: 0.8342\n",
      "Epoch 81/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4022 - accuracy: 0.8347\n",
      "Epoch 82/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4023 - accuracy: 0.8341\n",
      "Epoch 83/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4022 - accuracy: 0.8345\n",
      "Epoch 84/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4018 - accuracy: 0.8347\n",
      "Epoch 85/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4020 - accuracy: 0.8363\n",
      "Epoch 86/100\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4017 - accuracy: 0.8339\n",
      "Epoch 87/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4018 - accuracy: 0.8352\n",
      "Epoch 88/100\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4020 - accuracy: 0.8347\n",
      "Epoch 89/100\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4016 - accuracy: 0.8350\n",
      "Epoch 90/100\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4018 - accuracy: 0.8366\n",
      "Epoch 91/100\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4019 - accuracy: 0.8352\n",
      "Epoch 92/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4019 - accuracy: 0.8345\n",
      "Epoch 93/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4012 - accuracy: 0.8341\n",
      "Epoch 94/100\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4022 - accuracy: 0.8341\n",
      "Epoch 95/100\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4016 - accuracy: 0.8348\n",
      "Epoch 96/100\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4017 - accuracy: 0.8356\n",
      "Epoch 97/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4018 - accuracy: 0.8347\n",
      "Epoch 98/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4017 - accuracy: 0.8350\n",
      "Epoch 99/100\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4018 - accuracy: 0.8344\n",
      "Epoch 100/100\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4014 - accuracy: 0.8334\n",
      "Epoch 1/100\n",
      "6400/6400 [==============================] - 0s 74us/step - loss: 0.5862 - accuracy: 0.7955\n",
      "Epoch 2/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4362 - accuracy: 0.7972\n",
      "Epoch 3/100\n",
      "6400/6400 [==============================] - 0s 47us/step - loss: 0.4293 - accuracy: 0.7972\n",
      "Epoch 4/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4264 - accuracy: 0.7972\n",
      "Epoch 5/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.4243 - accuracy: 0.7972\n",
      "Epoch 6/100\n",
      "6400/6400 [==============================] - 0s 47us/step - loss: 0.4223 - accuracy: 0.7972\n",
      "Epoch 7/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.4203 - accuracy: 0.7972\n",
      "Epoch 8/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4189 - accuracy: 0.7972\n",
      "Epoch 9/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4173 - accuracy: 0.8152\n",
      "Epoch 10/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.8230\n",
      "Epoch 11/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4152 - accuracy: 0.8256\n",
      "Epoch 12/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4143 - accuracy: 0.8273\n",
      "Epoch 13/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4138 - accuracy: 0.8273\n",
      "Epoch 14/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4131 - accuracy: 0.8289\n",
      "Epoch 15/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4124 - accuracy: 0.8311\n",
      "Epoch 16/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4117 - accuracy: 0.8314\n",
      "Epoch 17/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4111 - accuracy: 0.8319\n",
      "Epoch 18/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4107 - accuracy: 0.8323\n",
      "Epoch 19/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4102 - accuracy: 0.8338\n",
      "Epoch 20/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4095 - accuracy: 0.8334\n",
      "Epoch 21/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4092 - accuracy: 0.8352\n",
      "Epoch 22/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4087 - accuracy: 0.8344\n",
      "Epoch 23/100\n",
      "6400/6400 [==============================] - 0s 47us/step - loss: 0.4082 - accuracy: 0.8344\n",
      "Epoch 24/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4078 - accuracy: 0.8361\n",
      "Epoch 25/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4077 - accuracy: 0.8342\n",
      "Epoch 26/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4072 - accuracy: 0.8353\n",
      "Epoch 27/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4068 - accuracy: 0.8356\n",
      "Epoch 28/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4064 - accuracy: 0.8358\n",
      "Epoch 29/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4061 - accuracy: 0.8352\n",
      "Epoch 30/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4059 - accuracy: 0.8383\n",
      "Epoch 31/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4054 - accuracy: 0.8369\n",
      "Epoch 32/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4046 - accuracy: 0.8342\n",
      "Epoch 33/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4035 - accuracy: 0.8369\n",
      "Epoch 34/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4027 - accuracy: 0.8363\n",
      "Epoch 35/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4018 - accuracy: 0.8372\n",
      "Epoch 36/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4013 - accuracy: 0.8369\n",
      "Epoch 37/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4005 - accuracy: 0.8355\n",
      "Epoch 38/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4003 - accuracy: 0.8373\n",
      "Epoch 39/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3993 - accuracy: 0.8375\n",
      "Epoch 40/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3990 - accuracy: 0.8369\n",
      "Epoch 41/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3987 - accuracy: 0.8366\n",
      "Epoch 42/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3985 - accuracy: 0.8366\n",
      "Epoch 43/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3976 - accuracy: 0.8370\n",
      "Epoch 44/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3968 - accuracy: 0.8377\n",
      "Epoch 45/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3972 - accuracy: 0.8369\n",
      "Epoch 46/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3965 - accuracy: 0.8372\n",
      "Epoch 47/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3961 - accuracy: 0.8364\n",
      "Epoch 48/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3961 - accuracy: 0.8372\n",
      "Epoch 49/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3952 - accuracy: 0.8375\n",
      "Epoch 50/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3950 - accuracy: 0.8369\n",
      "Epoch 51/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3948 - accuracy: 0.8383\n",
      "Epoch 52/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3946 - accuracy: 0.8372\n",
      "Epoch 53/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3942 - accuracy: 0.8363\n",
      "Epoch 54/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3941 - accuracy: 0.8363\n",
      "Epoch 55/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3936 - accuracy: 0.8377\n",
      "Epoch 56/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3936 - accuracy: 0.8370\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3936 - accuracy: 0.8366\n",
      "Epoch 58/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3930 - accuracy: 0.8370\n",
      "Epoch 59/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3930 - accuracy: 0.8363\n",
      "Epoch 60/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3933 - accuracy: 0.8377\n",
      "Epoch 61/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3930 - accuracy: 0.8369\n",
      "Epoch 62/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3930 - accuracy: 0.8370\n",
      "Epoch 63/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3928 - accuracy: 0.8373\n",
      "Epoch 64/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3925 - accuracy: 0.8377\n",
      "Epoch 65/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3922 - accuracy: 0.8373\n",
      "Epoch 66/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3921 - accuracy: 0.8355\n",
      "Epoch 67/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3914 - accuracy: 0.8359\n",
      "Epoch 68/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3916 - accuracy: 0.8381\n",
      "Epoch 69/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3908 - accuracy: 0.8389\n",
      "Epoch 70/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3906 - accuracy: 0.8369\n",
      "Epoch 71/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3904 - accuracy: 0.8386\n",
      "Epoch 72/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3892 - accuracy: 0.8378\n",
      "Epoch 73/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3887 - accuracy: 0.8389\n",
      "Epoch 74/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3872 - accuracy: 0.8405\n",
      "Epoch 75/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.3867 - accuracy: 0.8398\n",
      "Epoch 76/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3856 - accuracy: 0.8413\n",
      "Epoch 77/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3843 - accuracy: 0.8411\n",
      "Epoch 78/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3828 - accuracy: 0.8402\n",
      "Epoch 79/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3812 - accuracy: 0.8406\n",
      "Epoch 80/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3786 - accuracy: 0.8414\n",
      "Epoch 81/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3765 - accuracy: 0.8422\n",
      "Epoch 82/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3746 - accuracy: 0.8438\n",
      "Epoch 83/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3719 - accuracy: 0.8441\n",
      "Epoch 84/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3701 - accuracy: 0.8456\n",
      "Epoch 85/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3675 - accuracy: 0.8469\n",
      "Epoch 86/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3654 - accuracy: 0.8484\n",
      "Epoch 87/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3626 - accuracy: 0.8477\n",
      "Epoch 88/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3614 - accuracy: 0.8497\n",
      "Epoch 89/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3593 - accuracy: 0.8506\n",
      "Epoch 90/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3579 - accuracy: 0.8508\n",
      "Epoch 91/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3567 - accuracy: 0.8514\n",
      "Epoch 92/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3557 - accuracy: 0.8525\n",
      "Epoch 93/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3543 - accuracy: 0.8545\n",
      "Epoch 94/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3531 - accuracy: 0.8525\n",
      "Epoch 95/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3532 - accuracy: 0.8558\n",
      "Epoch 96/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3516 - accuracy: 0.8562\n",
      "Epoch 97/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3507 - accuracy: 0.8578\n",
      "Epoch 98/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3504 - accuracy: 0.8567\n",
      "Epoch 99/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3507 - accuracy: 0.8553\n",
      "Epoch 100/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3495 - accuracy: 0.8558\n",
      "Epoch 1/100\n",
      "6400/6400 [==============================] - 0s 65us/step - loss: 0.5827 - accuracy: 0.7887\n",
      "Epoch 2/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4374 - accuracy: 0.8020\n",
      "Epoch 3/100\n",
      "6400/6400 [==============================] - 0s 51us/step - loss: 0.4247 - accuracy: 0.8206\n",
      "Epoch 4/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4175 - accuracy: 0.8238\n",
      "Epoch 5/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.4120 - accuracy: 0.8281\n",
      "Epoch 6/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4066 - accuracy: 0.8295\n",
      "Epoch 7/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4017 - accuracy: 0.8297\n",
      "Epoch 8/100\n",
      "6400/6400 [==============================] - ETA: 0s - loss: 0.3970 - accuracy: 0.82 - 0s 46us/step - loss: 0.3974 - accuracy: 0.8273\n",
      "Epoch 9/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3938 - accuracy: 0.8289\n",
      "Epoch 10/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3900 - accuracy: 0.8298\n",
      "Epoch 11/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.3869 - accuracy: 0.8273\n",
      "Epoch 12/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3842 - accuracy: 0.8320\n",
      "Epoch 13/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3821 - accuracy: 0.8378\n",
      "Epoch 14/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3791 - accuracy: 0.8416\n",
      "Epoch 15/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3766 - accuracy: 0.8428\n",
      "Epoch 16/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3750 - accuracy: 0.8414\n",
      "Epoch 17/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3729 - accuracy: 0.8450\n",
      "Epoch 18/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3709 - accuracy: 0.8481\n",
      "Epoch 19/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3690 - accuracy: 0.8484\n",
      "Epoch 20/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3670 - accuracy: 0.8486\n",
      "Epoch 21/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3662 - accuracy: 0.8522\n",
      "Epoch 22/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3643 - accuracy: 0.8519\n",
      "Epoch 23/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3633 - accuracy: 0.8525\n",
      "Epoch 24/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3624 - accuracy: 0.8539\n",
      "Epoch 25/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3605 - accuracy: 0.8567\n",
      "Epoch 26/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3598 - accuracy: 0.8502\n",
      "Epoch 27/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3588 - accuracy: 0.8544\n",
      "Epoch 28/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3584 - accuracy: 0.8553\n",
      "Epoch 29/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3585 - accuracy: 0.8517\n",
      "Epoch 30/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3570 - accuracy: 0.8558\n",
      "Epoch 31/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3561 - accuracy: 0.8550\n",
      "Epoch 32/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3550 - accuracy: 0.8573\n",
      "Epoch 33/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3542 - accuracy: 0.8592\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3542 - accuracy: 0.8569\n",
      "Epoch 35/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3530 - accuracy: 0.8548\n",
      "Epoch 36/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.3527 - accuracy: 0.8575\n",
      "Epoch 37/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3519 - accuracy: 0.8581\n",
      "Epoch 38/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3515 - accuracy: 0.8581\n",
      "Epoch 39/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3513 - accuracy: 0.8598\n",
      "Epoch 40/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3506 - accuracy: 0.8600\n",
      "Epoch 41/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3491 - accuracy: 0.8581\n",
      "Epoch 42/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3486 - accuracy: 0.8586\n",
      "Epoch 43/100\n",
      "6400/6400 [==============================] - 0s 48us/step - loss: 0.3488 - accuracy: 0.8603\n",
      "Epoch 44/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.3483 - accuracy: 0.8597\n",
      "Epoch 45/100\n",
      "6400/6400 [==============================] - 0s 54us/step - loss: 0.3478 - accuracy: 0.8614\n",
      "Epoch 46/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3482 - accuracy: 0.8594\n",
      "Epoch 47/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3481 - accuracy: 0.8619\n",
      "Epoch 48/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3472 - accuracy: 0.8603\n",
      "Epoch 49/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3461 - accuracy: 0.8616\n",
      "Epoch 50/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3462 - accuracy: 0.8603\n",
      "Epoch 51/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3465 - accuracy: 0.8617\n",
      "Epoch 52/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3457 - accuracy: 0.8611\n",
      "Epoch 53/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3462 - accuracy: 0.8597\n",
      "Epoch 54/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3455 - accuracy: 0.8603\n",
      "Epoch 55/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3448 - accuracy: 0.8611\n",
      "Epoch 56/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3454 - accuracy: 0.8608\n",
      "Epoch 57/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3441 - accuracy: 0.8602\n",
      "Epoch 58/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3445 - accuracy: 0.8612\n",
      "Epoch 59/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3449 - accuracy: 0.8614\n",
      "Epoch 60/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3446 - accuracy: 0.8606\n",
      "Epoch 61/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3436 - accuracy: 0.8609\n",
      "Epoch 62/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3440 - accuracy: 0.8602\n",
      "Epoch 63/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3443 - accuracy: 0.8622\n",
      "Epoch 64/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3436 - accuracy: 0.8602\n",
      "Epoch 65/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3434 - accuracy: 0.8606\n",
      "Epoch 66/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3428 - accuracy: 0.8614\n",
      "Epoch 67/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3428 - accuracy: 0.8591\n",
      "Epoch 68/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3426 - accuracy: 0.8617\n",
      "Epoch 69/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3433 - accuracy: 0.8617\n",
      "Epoch 70/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3422 - accuracy: 0.8602\n",
      "Epoch 71/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3431 - accuracy: 0.8628\n",
      "Epoch 72/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3431 - accuracy: 0.8622\n",
      "Epoch 73/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3417 - accuracy: 0.8637\n",
      "Epoch 74/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3424 - accuracy: 0.8573\n",
      "Epoch 75/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3431 - accuracy: 0.8608\n",
      "Epoch 76/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3434 - accuracy: 0.8572\n",
      "Epoch 77/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3424 - accuracy: 0.8605\n",
      "Epoch 78/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3430 - accuracy: 0.8605\n",
      "Epoch 79/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3413 - accuracy: 0.8614\n",
      "Epoch 80/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3425 - accuracy: 0.8603\n",
      "Epoch 81/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3421 - accuracy: 0.8617\n",
      "Epoch 82/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3419 - accuracy: 0.8606\n",
      "Epoch 83/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3422 - accuracy: 0.8591\n",
      "Epoch 84/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3421 - accuracy: 0.8592\n",
      "Epoch 85/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3420 - accuracy: 0.8603\n",
      "Epoch 86/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3430 - accuracy: 0.8589\n",
      "Epoch 87/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3413 - accuracy: 0.8598\n",
      "Epoch 88/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3416 - accuracy: 0.8602\n",
      "Epoch 89/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.3420 - accuracy: 0.8628\n",
      "Epoch 90/100\n",
      "6400/6400 [==============================] - 0s 52us/step - loss: 0.3417 - accuracy: 0.8609\n",
      "Epoch 91/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3412 - accuracy: 0.8617\n",
      "Epoch 92/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.3416 - accuracy: 0.8614\n",
      "Epoch 93/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3416 - accuracy: 0.8614\n",
      "Epoch 94/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3414 - accuracy: 0.8617\n",
      "Epoch 95/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3415 - accuracy: 0.8602\n",
      "Epoch 96/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3423 - accuracy: 0.8609\n",
      "Epoch 97/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3406 - accuracy: 0.8623\n",
      "Epoch 98/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3423 - accuracy: 0.8595\n",
      "Epoch 99/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3405 - accuracy: 0.8609\n",
      "Epoch 100/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3413 - accuracy: 0.8637\n",
      "Epoch 1/100\n",
      "6400/6400 [==============================] - 0s 66us/step - loss: 0.5788 - accuracy: 0.7955\n",
      "Epoch 2/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4282 - accuracy: 0.8016\n",
      "Epoch 3/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4198 - accuracy: 0.8231\n",
      "Epoch 4/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4150 - accuracy: 0.8283\n",
      "Epoch 5/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4110 - accuracy: 0.8306\n",
      "Epoch 6/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4075 - accuracy: 0.8330\n",
      "Epoch 7/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4050 - accuracy: 0.8331\n",
      "Epoch 8/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4033 - accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4013 - accuracy: 0.8316\n",
      "Epoch 10/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3995 - accuracy: 0.8327\n",
      "Epoch 11/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3970 - accuracy: 0.8341\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3948 - accuracy: 0.8325\n",
      "Epoch 13/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3925 - accuracy: 0.8338\n",
      "Epoch 14/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3893 - accuracy: 0.8328\n",
      "Epoch 15/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3866 - accuracy: 0.8328\n",
      "Epoch 16/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3833 - accuracy: 0.8334\n",
      "Epoch 17/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3800 - accuracy: 0.8356\n",
      "Epoch 18/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3777 - accuracy: 0.8391\n",
      "Epoch 19/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3752 - accuracy: 0.8408\n",
      "Epoch 20/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3736 - accuracy: 0.8423\n",
      "Epoch 21/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3714 - accuracy: 0.8413\n",
      "Epoch 22/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3695 - accuracy: 0.8466\n",
      "Epoch 23/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.3683 - accuracy: 0.8466\n",
      "Epoch 24/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3668 - accuracy: 0.8475\n",
      "Epoch 25/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3650 - accuracy: 0.8487\n",
      "Epoch 26/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3640 - accuracy: 0.8514\n",
      "Epoch 27/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3631 - accuracy: 0.8503\n",
      "Epoch 28/100\n",
      "6400/6400 [==============================] - 0s 46us/step - loss: 0.3618 - accuracy: 0.8527\n",
      "Epoch 29/100\n",
      "6400/6400 [==============================] - 0s 48us/step - loss: 0.3608 - accuracy: 0.8523\n",
      "Epoch 30/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3596 - accuracy: 0.8512\n",
      "Epoch 31/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3586 - accuracy: 0.8527\n",
      "Epoch 32/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3573 - accuracy: 0.8537\n",
      "Epoch 33/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3565 - accuracy: 0.8552\n",
      "Epoch 34/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3552 - accuracy: 0.8522\n",
      "Epoch 35/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3543 - accuracy: 0.8537\n",
      "Epoch 36/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3535 - accuracy: 0.8534\n",
      "Epoch 37/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3515 - accuracy: 0.8556\n",
      "Epoch 38/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3515 - accuracy: 0.8566\n",
      "Epoch 39/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3508 - accuracy: 0.8558\n",
      "Epoch 40/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3503 - accuracy: 0.8553\n",
      "Epoch 41/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3498 - accuracy: 0.8583\n",
      "Epoch 42/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3486 - accuracy: 0.8561\n",
      "Epoch 43/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3485 - accuracy: 0.8569\n",
      "Epoch 44/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3474 - accuracy: 0.8577\n",
      "Epoch 45/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3476 - accuracy: 0.8575\n",
      "Epoch 46/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3472 - accuracy: 0.8569\n",
      "Epoch 47/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3475 - accuracy: 0.8570\n",
      "Epoch 48/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3456 - accuracy: 0.8583\n",
      "Epoch 49/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3451 - accuracy: 0.8575\n",
      "Epoch 50/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3458 - accuracy: 0.8589\n",
      "Epoch 51/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3446 - accuracy: 0.8575\n",
      "Epoch 52/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3449 - accuracy: 0.8561\n",
      "Epoch 53/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3448 - accuracy: 0.8581\n",
      "Epoch 54/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3445 - accuracy: 0.8606\n",
      "Epoch 55/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.3438 - accuracy: 0.8597\n",
      "Epoch 56/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3434 - accuracy: 0.8625\n",
      "Epoch 57/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3438 - accuracy: 0.8594\n",
      "Epoch 58/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3436 - accuracy: 0.8603\n",
      "Epoch 59/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3428 - accuracy: 0.8605\n",
      "Epoch 60/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3433 - accuracy: 0.8573\n",
      "Epoch 61/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3424 - accuracy: 0.8606\n",
      "Epoch 62/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3427 - accuracy: 0.8612\n",
      "Epoch 63/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3418 - accuracy: 0.8617\n",
      "Epoch 64/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3416 - accuracy: 0.8616\n",
      "Epoch 65/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3427 - accuracy: 0.8592\n",
      "Epoch 66/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3417 - accuracy: 0.8617\n",
      "Epoch 67/100\n",
      "6400/6400 [==============================] - 0s 60us/step - loss: 0.3421 - accuracy: 0.8591\n",
      "Epoch 68/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3422 - accuracy: 0.8611\n",
      "Epoch 69/100\n",
      "6400/6400 [==============================] - 0s 56us/step - loss: 0.3425 - accuracy: 0.8606\n",
      "Epoch 70/100\n",
      "6400/6400 [==============================] - 0s 50us/step - loss: 0.3415 - accuracy: 0.8608\n",
      "Epoch 71/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3418 - accuracy: 0.8605\n",
      "Epoch 72/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3409 - accuracy: 0.8598\n",
      "Epoch 73/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.3410 - accuracy: 0.8617\n",
      "Epoch 74/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.3417 - accuracy: 0.8595\n",
      "Epoch 75/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3411 - accuracy: 0.8605\n",
      "Epoch 76/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3411 - accuracy: 0.8623\n",
      "Epoch 77/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3407 - accuracy: 0.8594\n",
      "Epoch 78/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3415 - accuracy: 0.8589\n",
      "Epoch 79/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3405 - accuracy: 0.8605\n",
      "Epoch 80/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3411 - accuracy: 0.8612\n",
      "Epoch 81/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3401 - accuracy: 0.8594\n",
      "Epoch 82/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3404 - accuracy: 0.8614\n",
      "Epoch 83/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3401 - accuracy: 0.8608\n",
      "Epoch 84/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3405 - accuracy: 0.8603\n",
      "Epoch 85/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3401 - accuracy: 0.8589\n",
      "Epoch 86/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3396 - accuracy: 0.8631\n",
      "Epoch 87/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3391 - accuracy: 0.8587\n",
      "Epoch 88/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3419 - accuracy: 0.8589\n",
      "Epoch 89/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3405 - accuracy: 0.8602\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3399 - accuracy: 0.8616\n",
      "Epoch 91/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3403 - accuracy: 0.8609\n",
      "Epoch 92/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3393 - accuracy: 0.8623\n",
      "Epoch 93/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3395 - accuracy: 0.8606\n",
      "Epoch 94/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3403 - accuracy: 0.8592\n",
      "Epoch 95/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3399 - accuracy: 0.8597\n",
      "Epoch 96/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3400 - accuracy: 0.8600\n",
      "Epoch 97/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3401 - accuracy: 0.8614\n",
      "Epoch 98/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3396 - accuracy: 0.8591\n",
      "Epoch 99/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3386 - accuracy: 0.8633\n",
      "Epoch 100/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3395 - accuracy: 0.8600\n",
      "Epoch 1/100\n",
      "6400/6400 [==============================] - 0s 71us/step - loss: 0.5743 - accuracy: 0.7950\n",
      "Epoch 2/100\n",
      "6400/6400 [==============================] - 0s 49us/step - loss: 0.4369 - accuracy: 0.7958\n",
      "Epoch 3/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.4296 - accuracy: 0.7958\n",
      "Epoch 4/100\n",
      "6400/6400 [==============================] - 0s 46us/step - loss: 0.4266 - accuracy: 0.7958\n",
      "Epoch 5/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4242 - accuracy: 0.7958\n",
      "Epoch 6/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4218 - accuracy: 0.7958\n",
      "Epoch 7/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4197 - accuracy: 0.7958\n",
      "Epoch 8/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.4184 - accuracy: 0.8180\n",
      "Epoch 9/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.4172 - accuracy: 0.8233\n",
      "Epoch 10/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4160 - accuracy: 0.8269\n",
      "Epoch 11/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4151 - accuracy: 0.8281\n",
      "Epoch 12/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4142 - accuracy: 0.8284\n",
      "Epoch 13/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4134 - accuracy: 0.8297\n",
      "Epoch 14/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4128 - accuracy: 0.8308\n",
      "Epoch 15/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4121 - accuracy: 0.8319\n",
      "Epoch 16/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4115 - accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4108 - accuracy: 0.8342\n",
      "Epoch 18/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4103 - accuracy: 0.8339\n",
      "Epoch 19/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4099 - accuracy: 0.8353\n",
      "Epoch 20/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4093 - accuracy: 0.8345\n",
      "Epoch 21/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4090 - accuracy: 0.8338\n",
      "Epoch 22/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4083 - accuracy: 0.8348\n",
      "Epoch 23/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4081 - accuracy: 0.8338\n",
      "Epoch 24/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4076 - accuracy: 0.8352\n",
      "Epoch 25/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4072 - accuracy: 0.8358\n",
      "Epoch 26/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4072 - accuracy: 0.8353\n",
      "Epoch 27/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4065 - accuracy: 0.8352\n",
      "Epoch 28/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4064 - accuracy: 0.8359\n",
      "Epoch 29/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4062 - accuracy: 0.8355\n",
      "Epoch 30/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.4060 - accuracy: 0.8359\n",
      "Epoch 31/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4054 - accuracy: 0.8350\n",
      "Epoch 32/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4051 - accuracy: 0.8353\n",
      "Epoch 33/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4051 - accuracy: 0.8348\n",
      "Epoch 34/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4051 - accuracy: 0.8364\n",
      "Epoch 35/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4046 - accuracy: 0.8359\n",
      "Epoch 36/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.4045 - accuracy: 0.8361\n",
      "Epoch 37/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4045 - accuracy: 0.8359\n",
      "Epoch 38/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4041 - accuracy: 0.8355\n",
      "Epoch 39/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4042 - accuracy: 0.8359\n",
      "Epoch 40/100\n",
      "6400/6400 [==============================] - 0s 48us/step - loss: 0.4038 - accuracy: 0.8363\n",
      "Epoch 41/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.4038 - accuracy: 0.8364\n",
      "Epoch 42/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4037 - accuracy: 0.8363\n",
      "Epoch 43/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4035 - accuracy: 0.8366\n",
      "Epoch 44/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4033 - accuracy: 0.8358\n",
      "Epoch 45/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4034 - accuracy: 0.8366\n",
      "Epoch 46/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4030 - accuracy: 0.8350\n",
      "Epoch 47/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4029 - accuracy: 0.8363\n",
      "Epoch 48/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4030 - accuracy: 0.8367\n",
      "Epoch 49/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4032 - accuracy: 0.8364\n",
      "Epoch 50/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4028 - accuracy: 0.8361\n",
      "Epoch 51/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4025 - accuracy: 0.8361\n",
      "Epoch 52/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4022 - accuracy: 0.8359\n",
      "Epoch 53/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4023 - accuracy: 0.8358\n",
      "Epoch 54/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4025 - accuracy: 0.8370\n",
      "Epoch 55/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4023 - accuracy: 0.8366\n",
      "Epoch 56/100\n",
      "6400/6400 [==============================] - 0s 51us/step - loss: 0.4021 - accuracy: 0.8358\n",
      "Epoch 57/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4020 - accuracy: 0.8370\n",
      "Epoch 58/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4020 - accuracy: 0.8373\n",
      "Epoch 59/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4019 - accuracy: 0.8366\n",
      "Epoch 60/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4019 - accuracy: 0.8370\n",
      "Epoch 61/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4018 - accuracy: 0.8366\n",
      "Epoch 62/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4021 - accuracy: 0.8359\n",
      "Epoch 63/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4017 - accuracy: 0.8358\n",
      "Epoch 64/100\n",
      "6400/6400 [==============================] - 0s 47us/step - loss: 0.4019 - accuracy: 0.8367\n",
      "Epoch 65/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4017 - accuracy: 0.8367\n",
      "Epoch 66/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4014 - accuracy: 0.8359\n",
      "Epoch 67/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4016 - accuracy: 0.8364\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4015 - accuracy: 0.8364\n",
      "Epoch 69/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4013 - accuracy: 0.8358\n",
      "Epoch 70/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4011 - accuracy: 0.8359\n",
      "Epoch 71/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4015 - accuracy: 0.8345\n",
      "Epoch 72/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4012 - accuracy: 0.8361\n",
      "Epoch 73/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4008 - accuracy: 0.8366\n",
      "Epoch 74/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4011 - accuracy: 0.8369\n",
      "Epoch 75/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4014 - accuracy: 0.8363\n",
      "Epoch 76/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4008 - accuracy: 0.8364\n",
      "Epoch 77/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4013 - accuracy: 0.8366\n",
      "Epoch 78/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4011 - accuracy: 0.8364\n",
      "Epoch 79/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4009 - accuracy: 0.8361\n",
      "Epoch 80/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4011 - accuracy: 0.8377\n",
      "Epoch 81/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4005 - accuracy: 0.8358\n",
      "Epoch 82/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4008 - accuracy: 0.8367\n",
      "Epoch 83/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4010 - accuracy: 0.8366\n",
      "Epoch 84/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4006 - accuracy: 0.8359\n",
      "Epoch 85/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4008 - accuracy: 0.8370\n",
      "Epoch 86/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4005 - accuracy: 0.8366\n",
      "Epoch 87/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4007 - accuracy: 0.8367\n",
      "Epoch 88/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4005 - accuracy: 0.8366\n",
      "Epoch 89/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4003 - accuracy: 0.8369\n",
      "Epoch 90/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4007 - accuracy: 0.8364\n",
      "Epoch 91/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4005 - accuracy: 0.8366\n",
      "Epoch 92/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4006 - accuracy: 0.8358\n",
      "Epoch 93/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4004 - accuracy: 0.8373\n",
      "Epoch 94/100\n",
      "6400/6400 [==============================] - 0s 48us/step - loss: 0.4000 - accuracy: 0.8364\n",
      "Epoch 95/100\n",
      "6400/6400 [==============================] - 0s 49us/step - loss: 0.4002 - accuracy: 0.8353\n",
      "Epoch 96/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4005 - accuracy: 0.8353\n",
      "Epoch 97/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.4002 - accuracy: 0.8359\n",
      "Epoch 98/100\n",
      "6400/6400 [==============================] - 0s 46us/step - loss: 0.4003 - accuracy: 0.8369\n",
      "Epoch 99/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4005 - accuracy: 0.8361\n",
      "Epoch 100/100\n",
      "6400/6400 [==============================] - 0s 48us/step - loss: 0.4000 - accuracy: 0.8369\n",
      "Epoch 1/100\n",
      "6400/6400 [==============================] - 0s 61us/step - loss: 0.5714 - accuracy: 0.7980\n",
      "Epoch 2/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4415 - accuracy: 0.7980\n",
      "Epoch 3/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4309 - accuracy: 0.7980\n",
      "Epoch 4/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4263 - accuracy: 0.7980\n",
      "Epoch 5/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4228 - accuracy: 0.7980\n",
      "Epoch 6/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4199 - accuracy: 0.7980\n",
      "Epoch 7/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4178 - accuracy: 0.8102\n",
      "Epoch 8/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4165 - accuracy: 0.8266\n",
      "Epoch 9/100\n",
      "6400/6400 [==============================] - 0s 50us/step - loss: 0.4155 - accuracy: 0.8277\n",
      "Epoch 10/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4146 - accuracy: 0.8275\n",
      "Epoch 11/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4139 - accuracy: 0.8314\n",
      "Epoch 12/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4133 - accuracy: 0.8316\n",
      "Epoch 13/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4129 - accuracy: 0.8322\n",
      "Epoch 14/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4122 - accuracy: 0.8317\n",
      "Epoch 15/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4116 - accuracy: 0.8325\n",
      "Epoch 16/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4113 - accuracy: 0.8316\n",
      "Epoch 17/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4109 - accuracy: 0.8331\n",
      "Epoch 18/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4101 - accuracy: 0.8327\n",
      "Epoch 19/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4097 - accuracy: 0.8339\n",
      "Epoch 20/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4095 - accuracy: 0.8328\n",
      "Epoch 21/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4092 - accuracy: 0.8322\n",
      "Epoch 22/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4087 - accuracy: 0.8347\n",
      "Epoch 23/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4084 - accuracy: 0.8317\n",
      "Epoch 24/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4080 - accuracy: 0.8338\n",
      "Epoch 25/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4080 - accuracy: 0.8344\n",
      "Epoch 26/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4076 - accuracy: 0.8334\n",
      "Epoch 27/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4074 - accuracy: 0.8338\n",
      "Epoch 28/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4072 - accuracy: 0.8331\n",
      "Epoch 29/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4070 - accuracy: 0.8336\n",
      "Epoch 30/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4067 - accuracy: 0.8341\n",
      "Epoch 31/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4067 - accuracy: 0.8339\n",
      "Epoch 32/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4062 - accuracy: 0.8348\n",
      "Epoch 33/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4065 - accuracy: 0.8348\n",
      "Epoch 34/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4060 - accuracy: 0.8344\n",
      "Epoch 35/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4055 - accuracy: 0.8347\n",
      "Epoch 36/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4058 - accuracy: 0.8341\n",
      "Epoch 37/100\n",
      "6400/6400 [==============================] - 0s 52us/step - loss: 0.4054 - accuracy: 0.8347\n",
      "Epoch 38/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4056 - accuracy: 0.8353\n",
      "Epoch 39/100\n",
      "6400/6400 [==============================] - 0s 50us/step - loss: 0.4053 - accuracy: 0.8355\n",
      "Epoch 40/100\n",
      "6400/6400 [==============================] - 0s 54us/step - loss: 0.4052 - accuracy: 0.8345\n",
      "Epoch 41/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4052 - accuracy: 0.8350\n",
      "Epoch 42/100\n",
      "6400/6400 [==============================] - 0s 64us/step - loss: 0.4049 - accuracy: 0.8347\n",
      "Epoch 43/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.4046 - accuracy: 0.8344\n",
      "Epoch 44/100\n",
      "6400/6400 [==============================] - 0s 54us/step - loss: 0.4047 - accuracy: 0.8339\n",
      "Epoch 45/100\n",
      "6400/6400 [==============================] - 0s 52us/step - loss: 0.4048 - accuracy: 0.8359\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4049 - accuracy: 0.8359\n",
      "Epoch 47/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4042 - accuracy: 0.8344\n",
      "Epoch 48/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4046 - accuracy: 0.8353\n",
      "Epoch 49/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4041 - accuracy: 0.8358\n",
      "Epoch 50/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4042 - accuracy: 0.8345\n",
      "Epoch 51/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4040 - accuracy: 0.8342\n",
      "Epoch 52/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4038 - accuracy: 0.8350\n",
      "Epoch 53/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4040 - accuracy: 0.8339\n",
      "Epoch 54/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4041 - accuracy: 0.8341\n",
      "Epoch 55/100\n",
      "6400/6400 [==============================] - 0s 48us/step - loss: 0.4034 - accuracy: 0.8363\n",
      "Epoch 56/100\n",
      "6400/6400 [==============================] - 0s 47us/step - loss: 0.4037 - accuracy: 0.8350\n",
      "Epoch 57/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4036 - accuracy: 0.8355\n",
      "Epoch 58/100\n",
      "6400/6400 [==============================] - 0s 52us/step - loss: 0.4037 - accuracy: 0.8345\n",
      "Epoch 59/100\n",
      "6400/6400 [==============================] - 0s 53us/step - loss: 0.4036 - accuracy: 0.8358\n",
      "Epoch 60/100\n",
      "6400/6400 [==============================] - 0s 51us/step - loss: 0.4035 - accuracy: 0.8353\n",
      "Epoch 61/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4033 - accuracy: 0.8353\n",
      "Epoch 62/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4033 - accuracy: 0.8350\n",
      "Epoch 63/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4032 - accuracy: 0.8373\n",
      "Epoch 64/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4029 - accuracy: 0.8359\n",
      "Epoch 65/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4025 - accuracy: 0.8350\n",
      "Epoch 66/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4031 - accuracy: 0.8372\n",
      "Epoch 67/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4026 - accuracy: 0.8338\n",
      "Epoch 68/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4028 - accuracy: 0.8361\n",
      "Epoch 69/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4023 - accuracy: 0.8366\n",
      "Epoch 70/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4021 - accuracy: 0.8364\n",
      "Epoch 71/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4018 - accuracy: 0.8367\n",
      "Epoch 72/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.4018 - accuracy: 0.8339\n",
      "Epoch 73/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.4016 - accuracy: 0.8359\n",
      "Epoch 74/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4015 - accuracy: 0.8363\n",
      "Epoch 75/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4016 - accuracy: 0.8375\n",
      "Epoch 76/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4010 - accuracy: 0.8372\n",
      "Epoch 77/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4013 - accuracy: 0.8356\n",
      "Epoch 78/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4007 - accuracy: 0.8375\n",
      "Epoch 79/100\n",
      "6400/6400 [==============================] - 0s 46us/step - loss: 0.4013 - accuracy: 0.8347\n",
      "Epoch 80/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4008 - accuracy: 0.8356\n",
      "Epoch 81/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4006 - accuracy: 0.8380\n",
      "Epoch 82/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.4005 - accuracy: 0.8363\n",
      "Epoch 83/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4008 - accuracy: 0.8369\n",
      "Epoch 84/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4002 - accuracy: 0.8356\n",
      "Epoch 85/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4000 - accuracy: 0.8367\n",
      "Epoch 86/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4002 - accuracy: 0.8367\n",
      "Epoch 87/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.4000 - accuracy: 0.8380\n",
      "Epoch 88/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4000 - accuracy: 0.8370\n",
      "Epoch 89/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.3996 - accuracy: 0.8380\n",
      "Epoch 90/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3994 - accuracy: 0.8372\n",
      "Epoch 91/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3993 - accuracy: 0.8369\n",
      "Epoch 92/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3995 - accuracy: 0.8370\n",
      "Epoch 93/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3993 - accuracy: 0.8353\n",
      "Epoch 94/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3988 - accuracy: 0.8352\n",
      "Epoch 95/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3992 - accuracy: 0.8364\n",
      "Epoch 96/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3990 - accuracy: 0.8394\n",
      "Epoch 97/100\n",
      "6400/6400 [==============================] - 0s 49us/step - loss: 0.3994 - accuracy: 0.8370\n",
      "Epoch 98/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3988 - accuracy: 0.8389\n",
      "Epoch 99/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3988 - accuracy: 0.8364\n",
      "Epoch 100/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3988 - accuracy: 0.8394\n",
      "Epoch 1/100\n",
      "6400/6400 [==============================] - 0s 70us/step - loss: 0.5809 - accuracy: 0.7964\n",
      "Epoch 2/100\n",
      "6400/6400 [==============================] - 0s 46us/step - loss: 0.4429 - accuracy: 0.7972 0s - loss: 0.4464 - accuracy: 0.\n",
      "Epoch 3/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4321 - accuracy: 0.7972\n",
      "Epoch 4/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4279 - accuracy: 0.7972\n",
      "Epoch 5/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4245 - accuracy: 0.7972\n",
      "Epoch 6/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4223 - accuracy: 0.7972\n",
      "Epoch 7/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4200 - accuracy: 0.7972\n",
      "Epoch 8/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.4181 - accuracy: 0.8114\n",
      "Epoch 9/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4166 - accuracy: 0.8211\n",
      "Epoch 10/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4157 - accuracy: 0.8228\n",
      "Epoch 11/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4148 - accuracy: 0.8275\n",
      "Epoch 12/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4137 - accuracy: 0.8298\n",
      "Epoch 13/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4128 - accuracy: 0.8311\n",
      "Epoch 14/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4123 - accuracy: 0.8317\n",
      "Epoch 15/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4115 - accuracy: 0.8314\n",
      "Epoch 16/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.4106 - accuracy: 0.8330\n",
      "Epoch 17/100\n",
      "6400/6400 [==============================] - 0s 48us/step - loss: 0.4100 - accuracy: 0.8353\n",
      "Epoch 18/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4094 - accuracy: 0.8345\n",
      "Epoch 19/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4089 - accuracy: 0.8344\n",
      "Epoch 20/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4084 - accuracy: 0.8339\n",
      "Epoch 21/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4080 - accuracy: 0.8345\n",
      "Epoch 22/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4074 - accuracy: 0.8352\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4072 - accuracy: 0.8356\n",
      "Epoch 24/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4069 - accuracy: 0.8350\n",
      "Epoch 25/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4062 - accuracy: 0.8363\n",
      "Epoch 26/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4061 - accuracy: 0.8359\n",
      "Epoch 27/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4059 - accuracy: 0.8375\n",
      "Epoch 28/100\n",
      "6400/6400 [==============================] - 0s 47us/step - loss: 0.4057 - accuracy: 0.8359\n",
      "Epoch 29/100\n",
      "6400/6400 [==============================] - 0s 51us/step - loss: 0.4054 - accuracy: 0.8353\n",
      "Epoch 30/100\n",
      "6400/6400 [==============================] - 0s 50us/step - loss: 0.4051 - accuracy: 0.8356\n",
      "Epoch 31/100\n",
      "6400/6400 [==============================] - 0s 50us/step - loss: 0.4048 - accuracy: 0.8369\n",
      "Epoch 32/100\n",
      "6400/6400 [==============================] - 0s 50us/step - loss: 0.4041 - accuracy: 0.8380\n",
      "Epoch 33/100\n",
      "6400/6400 [==============================] - 0s 51us/step - loss: 0.4043 - accuracy: 0.8359\n",
      "Epoch 34/100\n",
      "6400/6400 [==============================] - 0s 55us/step - loss: 0.4042 - accuracy: 0.8361\n",
      "Epoch 35/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4036 - accuracy: 0.8370\n",
      "Epoch 36/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4036 - accuracy: 0.8356\n",
      "Epoch 37/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4036 - accuracy: 0.8380\n",
      "Epoch 38/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4027 - accuracy: 0.8370\n",
      "Epoch 39/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.4034 - accuracy: 0.8364\n",
      "Epoch 40/100\n",
      "6400/6400 [==============================] - 0s 56us/step - loss: 0.4031 - accuracy: 0.8355\n",
      "Epoch 41/100\n",
      "6400/6400 [==============================] - 0s 60us/step - loss: 0.4027 - accuracy: 0.8363\n",
      "Epoch 42/100\n",
      "6400/6400 [==============================] - 0s 48us/step - loss: 0.4027 - accuracy: 0.8359\n",
      "Epoch 43/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4022 - accuracy: 0.8361\n",
      "Epoch 44/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4024 - accuracy: 0.8361 0s - loss: 0.4133 - accuracy: \n",
      "Epoch 45/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4022 - accuracy: 0.8366\n",
      "Epoch 46/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4021 - accuracy: 0.8372\n",
      "Epoch 47/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4022 - accuracy: 0.8378\n",
      "Epoch 48/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4018 - accuracy: 0.8370\n",
      "Epoch 49/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.4016 - accuracy: 0.8361\n",
      "Epoch 50/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4014 - accuracy: 0.8369\n",
      "Epoch 51/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4015 - accuracy: 0.8341\n",
      "Epoch 52/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4014 - accuracy: 0.8373\n",
      "Epoch 53/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4014 - accuracy: 0.8355\n",
      "Epoch 54/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4009 - accuracy: 0.8361\n",
      "Epoch 55/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4013 - accuracy: 0.8364\n",
      "Epoch 56/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4007 - accuracy: 0.8370\n",
      "Epoch 57/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4012 - accuracy: 0.8364\n",
      "Epoch 58/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4010 - accuracy: 0.8369\n",
      "Epoch 59/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4005 - accuracy: 0.8359\n",
      "Epoch 60/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4007 - accuracy: 0.8358\n",
      "Epoch 61/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4006 - accuracy: 0.8367\n",
      "Epoch 62/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.4006 - accuracy: 0.8364\n",
      "Epoch 63/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4009 - accuracy: 0.8359\n",
      "Epoch 64/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4000 - accuracy: 0.8367\n",
      "Epoch 65/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4003 - accuracy: 0.8356\n",
      "Epoch 66/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4001 - accuracy: 0.8358\n",
      "Epoch 67/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4006 - accuracy: 0.8369\n",
      "Epoch 68/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4002 - accuracy: 0.8364\n",
      "Epoch 69/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4000 - accuracy: 0.8380\n",
      "Epoch 70/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4001 - accuracy: 0.8370\n",
      "Epoch 71/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4000 - accuracy: 0.8356\n",
      "Epoch 72/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4000 - accuracy: 0.8345\n",
      "Epoch 73/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3999 - accuracy: 0.8355\n",
      "Epoch 74/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.4000 - accuracy: 0.8356\n",
      "Epoch 75/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3993 - accuracy: 0.8372\n",
      "Epoch 76/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3991 - accuracy: 0.8380\n",
      "Epoch 77/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3994 - accuracy: 0.8352\n",
      "Epoch 78/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3995 - accuracy: 0.8366\n",
      "Epoch 79/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3997 - accuracy: 0.8356\n",
      "Epoch 80/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3994 - accuracy: 0.8363\n",
      "Epoch 81/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3996 - accuracy: 0.8348\n",
      "Epoch 82/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3993 - accuracy: 0.8350\n",
      "Epoch 83/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3991 - accuracy: 0.8348\n",
      "Epoch 84/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3994 - accuracy: 0.8352\n",
      "Epoch 85/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3995 - accuracy: 0.8350\n",
      "Epoch 86/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3993 - accuracy: 0.8361\n",
      "Epoch 87/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3993 - accuracy: 0.8363\n",
      "Epoch 88/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3992 - accuracy: 0.8372\n",
      "Epoch 89/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3993 - accuracy: 0.8356\n",
      "Epoch 90/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3989 - accuracy: 0.8363\n",
      "Epoch 91/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3994 - accuracy: 0.8344\n",
      "Epoch 92/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3986 - accuracy: 0.8352\n",
      "Epoch 93/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3995 - accuracy: 0.8369\n",
      "Epoch 94/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3988 - accuracy: 0.8342\n",
      "Epoch 95/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3985 - accuracy: 0.8355\n",
      "Epoch 96/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3991 - accuracy: 0.8378\n",
      "Epoch 97/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3985 - accuracy: 0.8347\n",
      "Epoch 98/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3993 - accuracy: 0.8353\n",
      "Epoch 99/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3986 - accuracy: 0.8377\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3990 - accuracy: 0.8334\n",
      "Epoch 1/100\n",
      "6400/6400 [==============================] - 0s 61us/step - loss: 0.6054 - accuracy: 0.7891\n",
      "Epoch 2/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4564 - accuracy: 0.7917\n",
      "Epoch 3/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4330 - accuracy: 0.7919\n",
      "Epoch 4/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4258 - accuracy: 0.8120\n",
      "Epoch 5/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4205 - accuracy: 0.8233\n",
      "Epoch 6/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.4161 - accuracy: 0.8248\n",
      "Epoch 7/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4116 - accuracy: 0.8264\n",
      "Epoch 8/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4071 - accuracy: 0.8263\n",
      "Epoch 9/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4029 - accuracy: 0.8267\n",
      "Epoch 10/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3992 - accuracy: 0.8277\n",
      "Epoch 11/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3961 - accuracy: 0.8269\n",
      "Epoch 12/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3934 - accuracy: 0.8284\n",
      "Epoch 13/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.3910 - accuracy: 0.8283\n",
      "Epoch 14/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.3888 - accuracy: 0.8302\n",
      "Epoch 15/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3866 - accuracy: 0.8298\n",
      "Epoch 16/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3845 - accuracy: 0.8280\n",
      "Epoch 17/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.3824 - accuracy: 0.8334\n",
      "Epoch 18/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.3802 - accuracy: 0.8400\n",
      "Epoch 19/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3787 - accuracy: 0.8417\n",
      "Epoch 20/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3771 - accuracy: 0.8439\n",
      "Epoch 21/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3756 - accuracy: 0.8428\n",
      "Epoch 22/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.3744 - accuracy: 0.8450\n",
      "Epoch 23/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3730 - accuracy: 0.8459\n",
      "Epoch 24/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.3719 - accuracy: 0.8484\n",
      "Epoch 25/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3700 - accuracy: 0.8475\n",
      "Epoch 26/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3697 - accuracy: 0.8480\n",
      "Epoch 27/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.3687 - accuracy: 0.8469\n",
      "Epoch 28/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3678 - accuracy: 0.8491\n",
      "Epoch 29/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3666 - accuracy: 0.8500\n",
      "Epoch 30/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.3656 - accuracy: 0.8516\n",
      "Epoch 31/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3648 - accuracy: 0.8495\n",
      "Epoch 32/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3641 - accuracy: 0.8519\n",
      "Epoch 33/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3630 - accuracy: 0.8517\n",
      "Epoch 34/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3627 - accuracy: 0.8533\n",
      "Epoch 35/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3620 - accuracy: 0.8542\n",
      "Epoch 36/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3608 - accuracy: 0.8548\n",
      "Epoch 37/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3606 - accuracy: 0.8525\n",
      "Epoch 38/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3596 - accuracy: 0.8522\n",
      "Epoch 39/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3589 - accuracy: 0.8542\n",
      "Epoch 40/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3589 - accuracy: 0.8555\n",
      "Epoch 41/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3583 - accuracy: 0.8558\n",
      "Epoch 42/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3575 - accuracy: 0.8586\n",
      "Epoch 43/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3564 - accuracy: 0.8561\n",
      "Epoch 44/100\n",
      "6400/6400 [==============================] - 0s 47us/step - loss: 0.3563 - accuracy: 0.8544\n",
      "Epoch 45/100\n",
      "6400/6400 [==============================] - 0s 53us/step - loss: 0.3551 - accuracy: 0.8584\n",
      "Epoch 46/100\n",
      "6400/6400 [==============================] - 0s 59us/step - loss: 0.3554 - accuracy: 0.8558\n",
      "Epoch 47/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3539 - accuracy: 0.8583\n",
      "Epoch 48/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3533 - accuracy: 0.8597\n",
      "Epoch 49/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3530 - accuracy: 0.8561\n",
      "Epoch 50/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3520 - accuracy: 0.8594\n",
      "Epoch 51/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3521 - accuracy: 0.8592\n",
      "Epoch 52/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3513 - accuracy: 0.8578\n",
      "Epoch 53/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3514 - accuracy: 0.8600\n",
      "Epoch 54/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3509 - accuracy: 0.8573\n",
      "Epoch 55/100\n",
      "6400/6400 [==============================] - 0s 46us/step - loss: 0.3504 - accuracy: 0.8589\n",
      "Epoch 56/100\n",
      "6400/6400 [==============================] - 0s 55us/step - loss: 0.3500 - accuracy: 0.8586\n",
      "Epoch 57/100\n",
      "6400/6400 [==============================] - 0s 56us/step - loss: 0.3496 - accuracy: 0.8575\n",
      "Epoch 58/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3485 - accuracy: 0.8600\n",
      "Epoch 59/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3492 - accuracy: 0.8587\n",
      "Epoch 60/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3476 - accuracy: 0.8600\n",
      "Epoch 61/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3481 - accuracy: 0.8595\n",
      "Epoch 62/100\n",
      "6400/6400 [==============================] - 0s 47us/step - loss: 0.3478 - accuracy: 0.8614\n",
      "Epoch 63/100\n",
      "6400/6400 [==============================] - 0s 51us/step - loss: 0.3471 - accuracy: 0.8617\n",
      "Epoch 64/100\n",
      "6400/6400 [==============================] - 0s 55us/step - loss: 0.3473 - accuracy: 0.8592\n",
      "Epoch 65/100\n",
      "6400/6400 [==============================] - 0s 48us/step - loss: 0.3463 - accuracy: 0.8611\n",
      "Epoch 66/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3459 - accuracy: 0.8606\n",
      "Epoch 67/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3465 - accuracy: 0.8614\n",
      "Epoch 68/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.3457 - accuracy: 0.8592\n",
      "Epoch 69/100\n",
      "6400/6400 [==============================] - 0s 50us/step - loss: 0.3459 - accuracy: 0.8619\n",
      "Epoch 70/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3460 - accuracy: 0.8619\n",
      "Epoch 71/100\n",
      "6400/6400 [==============================] - 0s 48us/step - loss: 0.3461 - accuracy: 0.8614\n",
      "Epoch 72/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.3450 - accuracy: 0.8611\n",
      "Epoch 73/100\n",
      "6400/6400 [==============================] - 0s 46us/step - loss: 0.3452 - accuracy: 0.8647\n",
      "Epoch 74/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.3450 - accuracy: 0.8598\n",
      "Epoch 75/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.3450 - accuracy: 0.8606\n",
      "Epoch 76/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3446 - accuracy: 0.8592\n",
      "Epoch 77/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3440 - accuracy: 0.8620\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3443 - accuracy: 0.8609\n",
      "Epoch 79/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3442 - accuracy: 0.8603\n",
      "Epoch 80/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3439 - accuracy: 0.8623\n",
      "Epoch 81/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3448 - accuracy: 0.8623\n",
      "Epoch 82/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3439 - accuracy: 0.8620\n",
      "Epoch 83/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3444 - accuracy: 0.8611\n",
      "Epoch 84/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3434 - accuracy: 0.8620\n",
      "Epoch 85/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3436 - accuracy: 0.8606\n",
      "Epoch 86/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3440 - accuracy: 0.8623\n",
      "Epoch 87/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3439 - accuracy: 0.8637\n",
      "Epoch 88/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3429 - accuracy: 0.8636\n",
      "Epoch 89/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3427 - accuracy: 0.8628\n",
      "Epoch 90/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3423 - accuracy: 0.8631\n",
      "Epoch 91/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3431 - accuracy: 0.8612\n",
      "Epoch 92/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3435 - accuracy: 0.8622\n",
      "Epoch 93/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3430 - accuracy: 0.8611\n",
      "Epoch 94/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3427 - accuracy: 0.8636\n",
      "Epoch 95/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3429 - accuracy: 0.8642\n",
      "Epoch 96/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3434 - accuracy: 0.8625\n",
      "Epoch 97/100\n",
      "6400/6400 [==============================] - 0s 47us/step - loss: 0.3429 - accuracy: 0.8602\n",
      "Epoch 98/100\n",
      "6400/6400 [==============================] - 0s 47us/step - loss: 0.3432 - accuracy: 0.8606\n",
      "Epoch 99/100\n",
      "6400/6400 [==============================] - 0s 46us/step - loss: 0.3428 - accuracy: 0.8605\n",
      "Epoch 100/100\n",
      "6400/6400 [==============================] - 0s 46us/step - loss: 0.3425 - accuracy: 0.8620\n",
      "Epoch 1/100\n",
      "6400/6400 [==============================] - 0s 78us/step - loss: 0.6339 - accuracy: 0.7944\n",
      "Epoch 2/100\n",
      "6400/6400 [==============================] - 0s 50us/step - loss: 0.4879 - accuracy: 0.7973\n",
      "Epoch 3/100\n",
      "6400/6400 [==============================] - 0s 49us/step - loss: 0.4384 - accuracy: 0.7973\n",
      "Epoch 4/100\n",
      "6400/6400 [==============================] - 0s 47us/step - loss: 0.4317 - accuracy: 0.7973\n",
      "Epoch 5/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.4283 - accuracy: 0.7973\n",
      "Epoch 6/100\n",
      "6400/6400 [==============================] - 0s 49us/step - loss: 0.4256 - accuracy: 0.7973\n",
      "Epoch 7/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.4228 - accuracy: 0.7973\n",
      "Epoch 8/100\n",
      "6400/6400 [==============================] - 0s 46us/step - loss: 0.4206 - accuracy: 0.7973\n",
      "Epoch 9/100\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.4181 - accuracy: 0.8130\n",
      "Epoch 10/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4156 - accuracy: 0.8269\n",
      "Epoch 11/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4133 - accuracy: 0.8297\n",
      "Epoch 12/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4113 - accuracy: 0.8323\n",
      "Epoch 13/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4099 - accuracy: 0.8338\n",
      "Epoch 14/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4082 - accuracy: 0.8341\n",
      "Epoch 15/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4068 - accuracy: 0.8345\n",
      "Epoch 16/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4058 - accuracy: 0.8358\n",
      "Epoch 17/100\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4047 - accuracy: 0.8355\n",
      "Epoch 18/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4040 - accuracy: 0.8364\n",
      "Epoch 19/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4035 - accuracy: 0.8361\n",
      "Epoch 20/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4029 - accuracy: 0.8353\n",
      "Epoch 21/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4024 - accuracy: 0.8364\n",
      "Epoch 22/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4020 - accuracy: 0.8380\n",
      "Epoch 23/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.4016 - accuracy: 0.8373\n",
      "Epoch 24/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4012 - accuracy: 0.8386 0s - loss: 0.3984 - accuracy: 0.\n",
      "Epoch 25/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4009 - accuracy: 0.8363\n",
      "Epoch 26/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4006 - accuracy: 0.8373\n",
      "Epoch 27/100\n",
      "6400/6400 [==============================] - 0s 53us/step - loss: 0.4006 - accuracy: 0.8369\n",
      "Epoch 28/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4001 - accuracy: 0.8370\n",
      "Epoch 29/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.4000 - accuracy: 0.8372\n",
      "Epoch 30/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3997 - accuracy: 0.8386\n",
      "Epoch 31/100\n",
      "6400/6400 [==============================] - 0s 69us/step - loss: 0.3994 - accuracy: 0.8378\n",
      "Epoch 32/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.3992 - accuracy: 0.8378\n",
      "Epoch 33/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3989 - accuracy: 0.8381\n",
      "Epoch 34/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3984 - accuracy: 0.8369\n",
      "Epoch 35/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3986 - accuracy: 0.8394\n",
      "Epoch 36/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3983 - accuracy: 0.8378 0s - loss: 0.4055 - accuracy: \n",
      "Epoch 37/100\n",
      "6400/6400 [==============================] - 0s 46us/step - loss: 0.3981 - accuracy: 0.8381\n",
      "Epoch 38/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3979 - accuracy: 0.8392\n",
      "Epoch 39/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3973 - accuracy: 0.8372\n",
      "Epoch 40/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3977 - accuracy: 0.8389\n",
      "Epoch 41/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3974 - accuracy: 0.8388\n",
      "Epoch 42/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3974 - accuracy: 0.8383\n",
      "Epoch 43/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3972 - accuracy: 0.8392\n",
      "Epoch 44/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3969 - accuracy: 0.8381\n",
      "Epoch 45/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3971 - accuracy: 0.8386\n",
      "Epoch 46/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3962 - accuracy: 0.8384\n",
      "Epoch 47/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3966 - accuracy: 0.8378\n",
      "Epoch 48/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3963 - accuracy: 0.8377\n",
      "Epoch 49/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3961 - accuracy: 0.8384\n",
      "Epoch 50/100\n",
      "6400/6400 [==============================] - 0s 54us/step - loss: 0.3966 - accuracy: 0.8386\n",
      "Epoch 51/100\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.3962 - accuracy: 0.8375\n",
      "Epoch 52/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3962 - accuracy: 0.8378\n",
      "Epoch 53/100\n",
      "6400/6400 [==============================] - 0s 69us/step - loss: 0.3958 - accuracy: 0.8373\n",
      "Epoch 54/100\n",
      "6400/6400 [==============================] - 0s 65us/step - loss: 0.3958 - accuracy: 0.8381\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 55us/step - loss: 0.3959 - accuracy: 0.8369\n",
      "Epoch 56/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.3957 - accuracy: 0.8373\n",
      "Epoch 57/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3956 - accuracy: 0.8383\n",
      "Epoch 58/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3957 - accuracy: 0.8366\n",
      "Epoch 59/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3954 - accuracy: 0.8381\n",
      "Epoch 60/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3953 - accuracy: 0.8384\n",
      "Epoch 61/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3953 - accuracy: 0.8378\n",
      "Epoch 62/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.3950 - accuracy: 0.8378\n",
      "Epoch 63/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3948 - accuracy: 0.8372\n",
      "Epoch 64/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3948 - accuracy: 0.8372\n",
      "Epoch 65/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3946 - accuracy: 0.8372\n",
      "Epoch 66/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3946 - accuracy: 0.8386\n",
      "Epoch 67/100\n",
      "6400/6400 [==============================] - 0s 67us/step - loss: 0.3943 - accuracy: 0.8388\n",
      "Epoch 68/100\n",
      "6400/6400 [==============================] - 0s 63us/step - loss: 0.3942 - accuracy: 0.8377\n",
      "Epoch 69/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.3943 - accuracy: 0.8392\n",
      "Epoch 70/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3941 - accuracy: 0.8388\n",
      "Epoch 71/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3939 - accuracy: 0.8389\n",
      "Epoch 72/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3937 - accuracy: 0.8394\n",
      "Epoch 73/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3934 - accuracy: 0.8391\n",
      "Epoch 74/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3931 - accuracy: 0.8384\n",
      "Epoch 75/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3929 - accuracy: 0.8398\n",
      "Epoch 76/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3928 - accuracy: 0.8397\n",
      "Epoch 77/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3924 - accuracy: 0.8392\n",
      "Epoch 78/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.3922 - accuracy: 0.8388\n",
      "Epoch 79/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.3918 - accuracy: 0.8398\n",
      "Epoch 80/100\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.3910 - accuracy: 0.8403\n",
      "Epoch 81/100\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.3903 - accuracy: 0.8392\n",
      "Epoch 82/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3895 - accuracy: 0.8384\n",
      "Epoch 83/100\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.3880 - accuracy: 0.8398\n",
      "Epoch 84/100\n",
      "6400/6400 [==============================] - 0s 44us/step - loss: 0.3870 - accuracy: 0.8377\n",
      "Epoch 85/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3858 - accuracy: 0.8386\n",
      "Epoch 86/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3841 - accuracy: 0.8378\n",
      "Epoch 87/100\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.3824 - accuracy: 0.8378\n",
      "Epoch 88/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3811 - accuracy: 0.8392\n",
      "Epoch 89/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3796 - accuracy: 0.8392\n",
      "Epoch 90/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3784 - accuracy: 0.8381\n",
      "Epoch 91/100\n",
      "6400/6400 [==============================] - 0s 40us/step - loss: 0.3768 - accuracy: 0.8381\n",
      "Epoch 92/100\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.3760 - accuracy: 0.8406\n",
      "Epoch 93/100\n",
      "6400/6400 [==============================] - 0s 46us/step - loss: 0.3748 - accuracy: 0.8397\n",
      "Epoch 94/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3735 - accuracy: 0.8394\n",
      "Epoch 95/100\n",
      "6400/6400 [==============================] - 0s 47us/step - loss: 0.3722 - accuracy: 0.8413\n",
      "Epoch 96/100\n",
      "6400/6400 [==============================] - 0s 53us/step - loss: 0.3714 - accuracy: 0.8436\n",
      "Epoch 97/100\n",
      "6400/6400 [==============================] - 0s 47us/step - loss: 0.3702 - accuracy: 0.8419\n",
      "Epoch 98/100\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.3697 - accuracy: 0.8425\n",
      "Epoch 99/100\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.3687 - accuracy: 0.8439\n",
      "Epoch 100/100\n",
      "2800/6400 [============>.................] - ETA: 0s - loss: 0.3666 - accuracy: 0.8379"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = model.best_params_\n",
    "best_accuracy = model.best_score_\n",
    "print(\"best_parameters:\",best_parameters,\"\\nbest_accuracy:\",best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='rmsprop',loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model is trained over 100 epochs\n",
    "model = classifier.fit(X_train,y_train,validation_split=0.2,batch_size=25,epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report and Confusion matrix Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy vs value accuracy\n",
    "model.history.keys()\n",
    "# summarize history for accuracy\n",
    "plt.plot(model.history['accuracy'])\n",
    "plt.plot(model.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],\n",
    "loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss vs value loss\n",
    "plt.plot(model.history['loss'])\n",
    "plt.plot(model.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],\n",
    "loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusion matrix and plotting: The confusion matrix is a two-dimensional array comparing predicted category labels to the true label. For binary classificaiton, these are the True Positive, True Negative, False Positive, and False Negative categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test.astype('int'),y_pred.astype('int'))\n",
    "sns.heatmap(conf_matrix,\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            square=True, \n",
    "            xticklabels=[\"not churn\",\"churn\"],\n",
    "            yticklabels=[\"not churn\",\"churn\"],\n",
    "            linewidths=2,\n",
    "            linecolor=\"w\",\n",
    "            cmap=\"Set1\")\n",
    "plt.subplots_adjust(wspace=.3,hspace=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Classification report is used to measure the quality of predictions from a classfication algorithm. How many predictions are Tre and how many are False. More specifically, True Positive, False Positives, True Negatives and False Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test.astype('int'),y_pred.astype('int')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implications:\n",
    "\n",
    "Banks could use this model on their own data and figure out the top 19.5% of their customers who are the most likely to leave the bank and use data mining to analyze those particular customers information. Analyzing this information can lead the bank into finding a similarity between the customers who were at the highest probability of leaving and take action to keep those customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF PROJECT"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
